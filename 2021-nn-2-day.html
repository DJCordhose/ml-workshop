<!doctype html>
<html>

<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">

    <title>Deep Learning</title>

    <link rel="stylesheet" href="reveal.js/css/reset.css">
    <link rel="stylesheet" href="reveal.js/css/reveal.css">
    <!-- <link rel="stylesheet" href="reveal.js/css/theme/black.css"> -->
    <link rel="stylesheet" href="reveal.js/css/theme/solarized.css">

    <!-- Theme used for syntax highlighting of code -->
    <link rel="stylesheet" href="reveal.js/lib/css/monokai.css">

    <style>
        /*pre code {*/
        /*display: block;*/
        /*padding: 0.5em;*/
        /*background: #FFFFFF !important;*/
        /*color: #000000 !important;*/
        /*}*/

        .right-img {
            margin-left: 10px !important;
            float: right;
            height: 500px;
        }

        .todo:before {
            content: 'TODO: ';
        }

        .todo {
            color: red !important;
        }

        code span.line-number {
            color: lightcoral;
        }

        .reveal pre code {
            max-height: 1000px !important;
        }

        img {
            border: 0 !important;
            box-shadow: 0 0 0 0 !important;
        }

        .reveal {
            -ms-touch-action: auto !important;
            touch-action: auto !important;
        }

        .reveal h2,
        .reveal h3,
        .reveal h4 {
            letter-spacing: 2px;
            font-family: 'Amiri', serif;
            /* font-family: 'Times New Roman', Times, serif; */
            font-weight: bold;
            font-style: italic;
            letter-spacing: -2px;
            text-transform: none !important;
        }

        .reveal em {
            font-weight: bold;
        }

        .reveal .step-subtitle h1 {
            letter-spacing: 1px;
        }

        .reveal .step-subtitle h2,
        .reveal .step-subtitle h3 {
            text-transform: none;
            font-style: italic;
            font-weight: normal;
            /* font-weight: 400; */
            /* font-family: 'Amiri', serif; */
            font-family: 'Lobster', serif;
            letter-spacing: 1px;
            color: #2aa198;
            text-decoration: underline;
        }

        .reveal .front-page h1,
        .reveal .front-page h2 {
            font-family: "League Gothic";
            font-style: normal;
            text-transform: uppercase !important;
            letter-spacing: 1px;
        }

        .reveal .front-page h1 {
            font-size: 2.5em !important;
        }

        .reveal .highlight {
            background-color: #D3337B;
            color: white;
        }

        .reveal section img {
            background: none;
        }

        .reveal img.with-border {
            border: 1px solid #586e75 !important;
            box-shadow: 3px 3px 1px rgba(0, 0, 0, 0.15) !important;
        }

        .reveal li {
            margin-bottom: 8px;
        }

        /* For li's that use FontAwesome icons as bullet-point */
        .reveal ul.fa-ul li {
            list-style-type: none;
        }
    </style>


    <!-- Printing and PDF exports -->
    <script>
        var link = document.createElement('link');
        link.rel = 'stylesheet';
        link.type = 'text/css';
        var printMode = window.location.search.match(/print-pdf/gi);
        link.href = printMode ? 'reveal.js/css/print/pdf.css' : 'reveal.js/css/print/paper.css';
        document.getElementsByTagName('head')[0].appendChild(link);
    </script>
</head>

<body>
    <div class="reveal">
        <div class="slides">
<!-- 
     
Agenda

Einführung in neuronale Netzwerke mit TensorFlow 2
Regression, Klassifikation, Metriken und Regularisierung

Supervised Deep Learning
Anwendungen von Deep Learning auf strukturierten Daten, Bilddaten und Zeitreihen

Unsupervised Deep Learning
Autoencoder und Embeddings

Deep Reinforcement Learning
Modellierung, Algorithmen und Anwendungen

 -->

 <section data-markdown class="todo">
    <textarea data-template>

 * Tag 1 mit Übungen in den Notebooks, 
 * Tag 2 aus dem Buch und Übungen in den Folien
   * oder aus dem Buch kopieren und anpassen?

 Dazu Folien drum herum auch für RNN, Tabular, VAE, GAN
</textarea>
</section>

<section data-markdown class="todo">
    <textarea data-template>
# Übersichtsfolie mit allen Notebooks

</textarea>
</section>


        <section data-markdown>
            <textarea data-template>
## Introduction to Deep Learning with TensorFlow 2                
<h4><a href="http://zeigermann.eu">Oliver Zeigermann</a> / 
    <a href="http://twitter.com/djcordhose">@DJCordhose</a>
</h4>

https://djcordhose.github.io/ml-workshop/2021-nn-2-day.html

            </textarea>
        </section>

<section data-markdown style="font-size: x-large;">
    <textarea data-template>
## Administratives

* Zeiten, Pausen
* Vorstellungsrunde
* Kontext und Erwartungen
* Google Colab (nur für den technischen Teil, heute Nachmittag): https://colab.research.google.com/

</textarea>
</section>
        
<section data-markdown>
    <textarea data-template>
## Schedule

1. Introduction to Deep Learning
1. Image Recognition
1. Unsupervised Deep Learning
1. Deep Reinforcement Learning

</textarea>
</section>

<section data-markdown style="font-size: x-large;">
    <textarea data-template>
### Topics

* Networks have predefined structures/architectures
* NN training loop
* loss functions
	* crossentropy
* optimizers
* training in batches
* evaluation methods
  * overfitting/generalization
  * training / test / validation split
  * confusion matrices
* basics of regularization for neural networks
* Dense Layers
* CNN Layers
* Relu
* Softmax

</textarea>
</section>

<section data-markdown>
    <textarea data-template>
### ML Models are restricted by their training data

<img src='img/ml-view-on-data.png' height="350px">

<small>

https://twitter.com/jacobmenick/status/1260658763687538688
</small>
    </textarea>
</section>

<section data-markdown>
    <textarea data-template>
### Models will only learn what you feed them

<img src='img/facebook-chatbot.png' height="350px">

<small>

https://twitter.com/TomerUllman/status/1259834838829465601
https://twitter.com/mikiobraun/status/1260115051417124869
</small>
    </textarea>
</section>

<section data-markdown>
    <textarea data-template>

Deep learning isn't a science, but rather an ever-changing set of empirically-derived engineering best practices, woven together by over-claiming, unreliable narratives.

https://twitter.com/fchollet/status/1333173017678028802
</textarea>
</section>

<section data-markdown>
    <textarea data-template>
## Schedule

1. _Introduction to Deep Learning_
1. Image Recognition
1. Unsupervised Deep Learning
1. Deep Reinforcement Learning

</textarea>
</section>

<section data-markdown style="font-size: xx-large;">
    <textarea data-template>
### Interactive introduction to Neural Networks with TensorFlow

https://colab.research.google.com/github/DJCordhose/ml-workshop/blob/master/notebooks/intro/2021/intro-deep-learning.ipynb?hl=en


Optional: https://colab.research.google.com/github/DJCordhose/ml-workshop/blob/master/notebooks/intro/nn-03-regularization.ipynb?hl=en

_Basics of Deep Learning, derived step by step_
</textarea>
</section>

<section data-markdown style="font-size: xx-large">
    <textarea data-template>
## Practical advice from a master of his craft

_Challenges of training neural nets_
1. Neural net training is a leaky abstraction - you need to understand what is going on
1. Neural net training fails silently - the possible error surface is large

_The recipe_
1. Understand your data
1. Make one simple experiment after the other
1. Make your model good / large enough to overfit on a batch
1. Regularize on full data set
1. Tune and scrape the barrel

<small>

https://karpathy.github.io/2019/04/25/recipe/    

</small>
</textarea>
</section>

<section data-markdown>
    <textarea data-template>
## Challenges of Deep Learning

* deep learning is more an art than a science
* we can provide guidelines as to what is likely to work or not
* ultimately every problem is unique 
* you will have to try and evaluate different strategies empirically
* currently there is no theory that will tell you in advance precisely what you should do to optimally solve a problem
* You must try and iterate

<small>

François Chollet in [Deep Learning with Python (Manning Publications)](https://www.manning.com/books/deep-learning-with-python?a_aid=keras&a_bid=76564dff)    

</small>

</textarea>
</section>

<section data-markdown>
ML researchers work with fixed benchmark datasets, and spend all of their time searching over the knobs they do control: architecture & optimization. In applied ML, you're likely to spend most of your time on data collection and annotation -- where your investment will pay off.

https://twitter.com/fchollet/status/1353421758699687942
    </section>    

<section data-markdown>
    <textarea data-template>
## Schedule

1. Introduction to Deep Learning
1. _Image Recognition_
1. Unsupervised Deep Learning
1. Deep Reinforcement Learning

</textarea>
</section>


<section data-markdown>
    <textarea data-template>
#### Even seemingly simple tasks are so far unsolved

recognizing digits and numbers in natural scene images

<img src='img/house_numbers.png' height="450px">

<small>

http://ufldl.stanford.edu/housenumbers/
</small>
    </textarea>
</section>



<section data-markdown style="font-size: xx-large;">
    <textarea data-template>
## Networks for Images

https://colab.research.google.com/github/DJCordhose/ml-workshop/blob/master/notebooks/intro/2021/intro_cnn.ipynb?hl=en

_A much more realistic example. How do you approach a challenge like this and how to you make it generalize to the real world._

Outdated version unsuccessfully trying transfer learning

https://colab.research.google.com/github/DJCordhose/ml-workshop/blob/master/notebooks/tf2/images-intro.ipynb

(just for the idea how to do that) 
</textarea>
</section>

<section data-markdown>
    <textarea data-template>
### Understanding CNNs  

_Network to process images_

<a href='https://poloclub.github.io/cnn-explainer/'>
<img src='img/cnn-explainer.png' height="400">
</a>
<small>

https://poloclub.github.io/cnn-explainer/
</small>
</textarea>
</section>

<section data-markdown class="todo">
* Auch RNN erwähnen
  * GRU als best practice
    
    </section>    


    <section data-markdown class="todo hide">
### Ende von Tag 1

Rezepte heraus holen
    
    </section>    

<section data-markdown>
    <textarea data-template>
### Composing Neural Networks

* input and output need to match training data and loss function
* some parts have clear function
  * mapping between dimensions, linear layer
  * Flatten, Reshape, BatchNorm, Dropout, Up-/Down-Sample
* the rest: 
  * soviet approach to aviation: add enough power until things become airborne

Oriol Vinyals - The Deep Learning toolkit in 2020:  https://youtu.be/-fdexQBpRas
</textarea>
</section>

<section data-markdown>
    <textarea data-template>
## Best Practices - Tabular data

* as a starting point
  * 3 hidden layers
  * 500 neurons per layer

* all hidden layers get ReLU activation
  * only change to something else if model does not train


</textarea>
</section>

<section data-markdown style="font-size: xx-large;">
    <textarea data-template>
## Best Practices - Image Data

* try a couple of standard architectures 
  * ResNet 50 can be a good starting point
  * transfer learning typically does not work
    * might only work if your image data is similar to ImageNet 
  * use large batch size and SGD as a means to force regularization
    * https://twitter.com/DJCordhose/status/1376140631555371008
* if standard model seems too complex or does not generalize try custom model
  * VGG subset with dropout and Batch Normalization might be a good candidate

https://keras.io/api/applications/
https://keras.io/api/applications/resnet/#resnet50v2-function

</textarea>
</section>

<section data-markdown style="font-size: xx-large;">
    <textarea data-template>
## Losses

* regression: linear (or any other activation if the range of values is limited) activation and MSE 
* two class: sigmoid activation and binary cross entropy
* multi class: softmax activation with categorical cross entropy
* multi-label: sigmoid activation and binary cross entropy, each output node would encode an hypothesis of its own

https://stats.stackexchange.com/questions/260505/should-i-use-a-categorical-cross-entropy-or-binary-cross-entropy-loss-for-binary
https://towardsdatascience.com/cross-entropy-for-classification-d98e7f974451

<!-- 
https://gombru.github.io/2018/05/23/cross_entropy_loss/
https://machinelearningmastery.com/how-to-choose-loss-functions-when-training-deep-learning-neural-networks/
https://towardsdatascience.com/understanding-binary-cross-entropy-log-loss-a-visual-explanation-a3ac6025181a
https://www.youtube.com/watch?v=ErfnhcEV1O8
https://towardsdatascience.com/cross-entropy-for-classification-d98e7f974451
 -->
</textarea>
</section>



<section data-markdown>
    <textarea data-template>
## Schedule

1. Introduction to Deep Learning
1. Image Recognition
1. _Unsupervised Deep Learning_
1. Deep Reinforcement Learning

</textarea>
</section>

<section data-markdown class="todo">
Wie im Buch und M3 Talk
Notebook aus dem Buch nehmen
Allgemeines Zeug nur in den Folien aus den Autoencoder Folien
Auch Anomgram (darauf optional nochmal zurück kommen)
Mit interaktiven Beispielen wann immer möglich

Unsupervised Deep Learning
Auch VAE, GAN, Boltzman Maschine

* Für Autoencoder-Beispiel auch mit UMAP auf 2D bringen und anzeigen

- Auf Englisch
- Übungen direkt im Notebook

    </section>    


<section data-markdown style="font-size: xx-large;">
    <textarea data-template>
## Introduction to Autoencoders

Von hier ableiten
https://colab.research.google.com/drive/1Vvvp3j802JEL0lOay4eC-FB_ttkFFxPr#scrollTo=j6tt1Z9cEV9m

https://colab.research.google.com/github/DJCordhose/ml-workshop/blob/master/notebooks/intro/2021/intro_autoencoder.ipynb?hl=en

</textarea>
</section>


<section data-markdown>
    <textarea data-template>
## Schedule

1. Introduction to Deep Learning
1. Image Recognition
1. Unsupervised Deep Learning
1. _Deep Reinforcement Learning_

</textarea>
</section>

<section data-markdown class="todo">
- Wie im Buch und den Workshops
- Grafiken aus Buch nehmen und auch getting started open ai nehmen
- Übungen im Notebook wie sonst im Workshop

</section>    
    



<section data-markdown class="fragments">
### Reinforcement Learning

* special position in the field of machine learning
* does not rely on existing data here
* generates data in experiments
* experiments conducted in simulation or in the real world, if safel and in large numbers
* experiments depend on desired outcome
* desired outcome which formally defined by rewards
* corresponds most closely to what many people intuitively imagine as intelligent behavior: learning more or less independently based on experience

</section>    

<section data-markdown class="fragments">
### State of Reinforcement Learning

* still rather academic
* computer or board typical academic application
* algorithm is central and important for academics
* practical applications include 
  * optimization
  * robotics
  * multi-armed bandits as a more general form of A/B testing
</section>    

<section data-markdown>
<textarea data-template>
### Real challenge is to model the problem for RL

<div  style="max-width: 45%; float: left">
<br>
<img src='img/rl2/rl.png'>
</div>
<div style="max-width: 50%; float: right">
<br>
<ol>
    <li>Based on <em>Observations</em> an <em>Agent</em> executes </li>
<li> <em>Actions</em> within a given  
<li><em>Environment</em> which lead to positive or negative 
<li><em>Rewards</em>.
</ol>
</div>

<div style="clear: both;">
    <br>
    <p >The Agent’s job is to maximize the cumulative Reward</p>
</div>

http://gym.openai.com/docs/

</textarea>
</section>

<section data-markdown>
    <textarea data-template>
### Our Application

<img src='img/rl2/orso.png' height="500">

</textarea>
</section>

<section data-markdown class="fragments">
    <textarea data-template>
### Shared Exercise: How to model as an RL problem?

- Objective: What should be achieved? When is an episode over?
- Environment: Who or what provides observations and rewards? Typically a simulation or the real world.
- Actions: What are the possible actions of the agent?
- Agent: Who or what chooses actions?
- Observations: What does the environment indicate to the agent?
- Rewards: What are the rewards and how much are they?

</textarea>
</section>

<section data-markdown>
    <textarea data-template>
### Sample/Reference Solution: Objective

* find the least strenuous way through the territory
* eat all the honey 
* finally get back to the cave
* after a certain number of steps we abort the episode without success
</textarea>
</section>

<section data-markdown>
    <textarea data-template>
### Sample/Reference Solution: Environment

Software simulation of the bear's territory
</textarea>
</section>

<section data-markdown class="fragments">
    <textarea data-template>
### Sample/Reference Solution: Actions

* 4 discrete actions in the style of an Atari game:
  * left
  * right
  * up
  * down
* doing nothing is not an option
  * the bear never learns that staying in the cave and just sleeping on might be an interesting solution to the problem
</textarea>
</section>

<section data-markdown>
    <textarea data-template>
### Sample/Reference Solution: Agent: 

The bear
* how this looks like technically we have to discuss later
</textarea>
</section>

<section data-markdown class="fragments">
    <textarea data-template>
### Sample/Reference Solution: Observations

* we show the bear only the part of its territory that it can see from its current position (partially observed)
* such an observation makes the problem more challenging
* just as we would have to explore the game situation in such a game, the bear would have to do the same in many playthroughs
* we choose this variant to demonstrate the power of reinforcement learning

_More details in Notebook_

</textarea>
</section>

<section data-markdown class="fragments">
    <textarea data-template>
### Sample/Reference Solution: Rewards

* for each step we combine different rewards 
* normalize them by the theoretical number of points to be achieved
* namely the sum of the rewards of all honey pots.
* reward always below 1
* if it is negative there was only cost, no reward.
* different costs per path are modeled
* honey is attractive to collect even if the path is expensive
* otherwise the incentive for the bear is not there

</textarea>
</section>


<section data-markdown>
    <textarea data-template>
### There are a lot of algorithms

<img src='img/rl_algorithms_9_15.svg'>
<small>

https://spinningup.openai.com/en/latest/spinningup/rl_intro2.html    

</small>

</textarea>
</section>

<section data-markdown>
    <textarea data-template>
### For practical work PPO is the algorithm to choose when creating samples is inexpensive

* if samples are expensive SAC might be best choice
* for our example sampling is cheap

https://spinningup.openai.com/en/latest/algorithms/ppo.html

</textarea>
</section>    


<section data-markdown>
    <textarea data-template>
### PPO (Proximal Policy Optimization)

<img src='img/rl2/ppo.png'>

</textarea>
</section>    

<section data-markdown>
    <textarea data-template>
### Deep Reinforcement Learning with PPO

<img src='img/rl2/drl-ppo.png'>

<small><em>
PPO uses two networks
</em></small>
    
</textarea>
</section>

<section data-markdown>
    <textarea data-template>
### Special Loss in PPO

* most advanced and practical variant of policy gradient branch
* uses vanilla backpropagation for training
* has special loss consisting of many parts
* turns hard constraints into penalties 
* uses value function to have better generalization

<small><em>
More details in Notebook
</em></small>
    
</textarea>
</section>

<section data-markdown>
    <textarea data-template>
### Policy Loss

_which action to perform_

<img src='img/rl2/policy_loss.png' height="500">

<small><em>
</em></small>
    
</textarea>
</section>

<section data-markdown>
    <textarea data-template>
### Value Loss

_prediction of reward_

<img src='img/rl2/value_loss.png' height="500">

</textarea>
</section>

<section data-markdown>
    <textarea data-template>
### KL Loss

_prevent catatrophic updates_
    
<img src='img/rl2/kl_loss.png' height="500">

    
</textarea>
</section>

<section data-markdown>
    <textarea data-template>
### Entropy Loss

_trade exploitation for exploration over time_

<img src='img/rl2/entropy_loss.png' height="500">

</textarea>
</section>

<section data-markdown style="font-size: xx-large;">
    <textarea data-template>
## Introduction to Deep Reinforcement Learning

Von hier ableiten
https://colab.research.google.com/drive/12vF2vSZdj4dnlK1aceC_NvYGyrcuh2cz?hl=en

https://colab.research.google.com/github/DJCordhose/ml-workshop/blob/master/notebooks/intro/2021/intro_rl.ipynb?hl=en

</textarea>
</section>



<section data-markdown>
        <textarea data-template>
# Finally
    
</textarea>
</section>

<section data-markdown style="font-size: xx-large;">
    <textarea data-template>
## Teaching Resources by Keras author François Chollet

* https://keras.io/getting_started/
* A list of up-to-date Keras examples in one place: https://keras.io/examples/
* A list of in-depth guides to learn modern Keras: https://keras.io/guides/

<!-- * Intro to Keras for Researchers: https://colab.research.google.com/drive/169PfzM0kvtA5UP4k6Sl1yCG9tsE2MLia
* Intro to Keras for Engineers: https://colab.research.google.com/drive/1lWUGZarlbORaHYUZlF9muCgpPl8pEvve
* Image classification from scratch: https://colab.research.google.com/drive/1umJnCp8tZ7UDTYSQsuWdKRhqbHts38AC
* Deep Dream:  https://colab.research.google.com/drive/18XPdEDVYdr_ODAvW0DrWRCRC25tvTuCE
* Activation Maps:  https://colab.research.google.com/drive/1CJQSVaXG1ceBQGFrTHnt-pt1xjO4KFDe
* Transfer Learning:  https://colab.research.google.com/drive/17vHSAj7no7RMdJ18MJomTf8twqw1suYC
* VAE:  https://colab.research.google.com/drive/1COeSoasrpY-w3uF1JPVksLEjx4Tx2ns5 -->

                            </textarea>
    </section>

<section data-markdown style="font-size: xx-large;">
    <textarea data-template>
## More Teaching Resources

* https://www.tensorflow.org/guide
* https://github.com/parrt/fundamentals-of-deep-learning
* Short and practical introduction to data science: https://github.com/rasbt/data-science-tutorial
* Fundamentals of Machine Learning and Deep Learning in Python using Scikit-Learn, Keras and TensorFlow 2: https://github.com/ageron/handson-ml2
* CS231n: Convolutional Neural Networks for Visual Recognition: http://cs231n.stanford.edu/
* CS224n: Natural Language Processing with Deep Learning: http://web.stanford.edu/class/cs224n/index.html#schedule


</textarea>
    </section>


         <!-- <section data-markdown style="font-size: xx-large;">
            <textarea data-template>
### Finding data sets to play with
    
* Google released a search engine for datasets
  * Search: https://toolbox.google.com/datasetsearch
  * Launch blog post: https://www.blog.google/products/search/making-it-easier-discover-datasets/
* Kaggle Datasets: https://www.kaggle.com/datasets
* TensorFlow Datasets: https://medium.com/tensorflow/introducing-tensorflow-datasets-c7f01f7e19f3
* https://www.openml.org/search?type=data
* https://github.com/jbrownlee/Datasets
</textarea>
</section> -->

        </div>
    </div>

    <script src="reveal.js/js/reveal.js"></script>
    <script src="lib/jquery-2.2.4.js"></script>

    <script>
        $('section:not([data-background])').attr('data-background', "background/white.jpg");
    </script>
    <script>
        const isLocal = window.location.hostname.indexOf('localhost') !== -1 || 
                    window.location.hostname.indexOf('127.0.0.1') !== -1;

        $('.hide').remove();

        if (isLocal && !printMode) {
        } else {
            // only applies to public version
                $('.todo').remove();
                $('.preparation').remove();
                $('.local').remove();
        }
    
        Reveal.addEventListener( 'ready', function( event ) {
            // applies to all versions
            $('code').addClass('line-numbers');
    
            $('.fragments li').addClass('fragment')
    
            // make all links open in new tab
            $('a').attr('target', '_blank')
    
            if (isLocal && !printMode) {
                // only applies to presentation version
                Reveal.configure({ controls: false });
            } else {
                // only applies to public version
                $('.fragment').removeClass('fragment');
            }
    
    
        } );
    </script>
    
    <script>
        // More info about config & dependencies:
        // - https://github.com/hakimel/reveal.js#configuration
        // - https://github.com/hakimel/reveal.js#dependencies
        Reveal.initialize({
            controls: true,
            progress: false,
            history: true,
            center: true,
            width: 1100,

            math: {
                mathjax: 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js',
                config: 'TeX-AMS_HTML-full'  // See http://docs.mathjax.org/en/latest/config-files.html
            },

            dependencies: [
                { src: 'reveal.js/plugin/markdown/marked.js' },
                { src: 'reveal.js/plugin/markdown/markdown.js' },
                { src: 'reveal.js/plugin/notes/notes.js', async: true },
                { src: 'reveal.js/plugin/highlight/highlight.js', async: true },
                { src: 'lib/js/line-numbers.js' },
                { src: 'reveal.js/plugin/math/math.js', async: true }
            ]
        });
    </script>
</body>

</html>