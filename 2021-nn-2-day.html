<!doctype html>
<html lang="de">

<head>
    <meta charset="utf-8">

    <title>Workshop Deep Learning</title>

    <meta name="description" content="Workshop Deep Learning?">
    <meta name="author" content="Oliver Zeigermann">
	<link rel="shortcut icon" href="/img/favicon.ico" >

    <meta name="apple-mobile-web-app-capable" content="yes"/>
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent"/>

    <meta name="viewport"
          content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, minimal-ui">

          <link rel="stylesheet" href="reveal.js/css/reveal.css">
          <link rel="stylesheet" href="reveal.js/css/theme/white.css" id="theme">
          <!--<link rel="stylesheet" href="reveal.js/css/theme/black.css" id="theme">-->
          <!--<link rel="stylesheet" href="reveal.js/css/theme/night.css" id="theme">-->
          <!--<link rel="stylesheet" href="reveal.js/css/theme/simple.css" id="theme">-->
          <!-- <link rel="stylesheet" href="reveal.js/css/theme/solarized.css" id="theme"> -->
      
          <link href="https://fonts.googleapis.com/css?family=Work+Sans:400,700" rel="stylesheet">

            <!-- Theme used for syntax highlighting of code -->
            <link rel="stylesheet" href="reveal.js/lib/css/monokai.css">
          <style>
              /*pre code {*/
                  /*display: block;*/
                  /*padding: 0.5em;*/
                  /*background: #FFFFFF !important;*/
                  /*color: #000000 !important;*/
              /*}*/
      
            @font-face {
                font-family: Sunrise;
                src: url("Sunrise International_special.ttf") format("opentype");
            }

              .right-img {
                  margin-left: 10px !important;
                  float: right;
                  height: 500px;
              }
              .todo:before {
                  content: 'TODO: ';
              }
              .todo {
                  color: red !important;
              }
              code span.line-number {
                  color: lightcoral;
              }
              .reveal pre code {
                  max-height: 1000px !important;
              }
      
              img {
                  border: 0 !important;
                  box-shadow:0 0 0 0 !important;
              }
      
              .reveal {
                  -ms-touch-action: auto !important;
                  touch-action: auto !important;
                      }

                .reveal h1,
                .reveal h2,
                .reveal h3,
                .reveal h4  {
                        /* letter-spacing: 2px; */
                        font-family: 'Calibri', sans-serif;
                          /* font-family: 'Times New Roman', Times, serif; */
                          /* font-weight: bold; */
                          color: black;
                          /* font-style: italic; */
                          /* letter-spacing: -2px; */
                          text-transform: none !important;
                      }
      
                      .reveal em {
                          font-weight: bold;
                      }
      
              .reveal section img {
                background: none;
              }
      
                      .reveal img.with-border {
                          border: 1px solid #586e75 !important;
                          box-shadow: 3px 3px 1px rgba(0, 0, 0, 0.15) !important;
                      }
      
                      .reveal li {
                          margin-bottom: 8px;
                      }
      
                      /* For li's that use FontAwesome icons as bullet-point */
                  .reveal ul.fa-ul li {
                      list-style-type: none;
                  }

            .reveal {
                /* font-family: 'Work Sans', 'Calibri'; */
                font-family: 'Calibri';
                color: black !important;
                /* font-size: xx-large; */
             }

          </style>
      
    <!-- Printing and PDF exports -->
    <script>
        var link = document.createElement('link');
        link.rel = 'stylesheet';
        link.type = 'text/css';
        var printMode = window.location.search.match(/print-pdf/gi);
        link.href = printMode ? 'reveal.js/css/print/pdf.css' : 'reveal.js/css/print/paper.css';
        document.getElementsByTagName('head')[0].appendChild(link);
    </script>

    <!--[if lt IE 9]>
    <script src="reveal.js/lib/js/html5shiv.js"></script>
    <![endif]-->
</head>

<body style="background-color: whitesmoke;">

    <div class="reveal">
        <div class="slides">
<!-- 
     
Agenda

Einführung in neuronale Netzwerke mit TensorFlow 2
Regression, Klassifikation, Metriken und Regularisierung

Supervised Deep Learning
Anwendungen von Deep Learning auf strukturierten Daten, Bilddaten und Zeitreihen

Unsupervised Deep Learning
Autoencoder und Embeddings

Deep Reinforcement Learning
Modellierung, Algorithmen und Anwendungen

 -->


 <section data-markdown class="todo">
- RL Übungen im Notebook wie sonst im Workshop

- [ ] Bessere Übungen für Autoencoder und RL
	- [ ] kleinere Dinge
	- [ ] Zwischenübung
    - Nicht im Notebook

- Folien aus M3 Autoencoder Talk hier nach der endgültigen Version des Talks übersetzen und einfügen        

</section>    
        
    
        <section data-markdown>
            <textarea data-template>
## Introduction to Deep Learning with TensorFlow 2                
<h4><a href="http://zeigermann.eu">Oliver Zeigermann</a> / 
    <a href="http://twitter.com/djcordhose">@DJCordhose</a>
</h4>

https://djcordhose.github.io/ml-workshop/2021-nn-2-day.html

            </textarea>
        </section>

<section data-markdown>
    <textarea data-template>
## Administratives

* Zeiten, Pausen
* Vorstellungsrunde
* Kontext und Erwartungen
* Google Colab: https://colab.research.google.com/

</textarea>
</section>

<section data-markdown style="font-size: xx-large;">
    <textarea data-template>

Agenda:
* Einführung in neuronale Netzwerke mit TensorFlow 2: Regression, Klassifikation, Metriken
  * Für 2-Tage: nur als Folien Regression
  * Für 3-Tage: Regression und Regularization nochmal als eigene Notebooks (+0,5 Tage)
* Supervised Deep Learning auf tabellarischen Daten, Bilddaten, Zeitreihen
  * Für 2-Tage: nur als Folien Zeitreihen
  * Für 2-Tage: tabellarischen Daten schon in Einführung abgedeckt
  * Für 3-Tage: Zeitreihen und Versicherungsbeispiel mit Notebooks (+0,5 Tage)
* Unsupervised Deep Learning: Autoencoder, Embeddings, 
  * VAEs, GANs nur als Folien und interaktive Sandboxes
* Deep Reinforcement Learning: Modellierung, Algorithmen, Anwendungen         
</textarea>
</section>


<section data-markdown>
    <textarea data-template>
## Schedule

1. Introduction to Deep Learning
1. Image Recognition
1. Unsupervised Deep Learning
1. Deep Reinforcement Learning

</textarea>
</section>

<section data-markdown style="font-size: x-large;">
    <textarea data-template>
### Topics

* Networks have predefined structures/architectures
* NN training loop
* loss functions
	* crossentropy
* optimizers
* training in batches
* evaluation methods
  * overfitting/generalization
  * training / test / validation split
  * confusion matrices
* basics of regularization for neural networks
* Dense Layers
* CNN Layers
* Relu
* Softmax

</textarea>
</section>

<section data-markdown>
    <textarea data-template>
### ML Models are restricted by their training data

<img src='img/ml-view-on-data.png' height="350px">

<small>

https://twitter.com/jacobmenick/status/1260658763687538688
</small>
    </textarea>
</section>

<section data-markdown>
    <textarea data-template>
### Models will only learn what you feed them

<img src='img/facebook-chatbot.png' height="350px">

<small>

https://twitter.com/TomerUllman/status/1259834838829465601
https://twitter.com/mikiobraun/status/1260115051417124869
</small>
    </textarea>
</section>

<section data-markdown>
    <textarea data-template>

Deep learning isn't a science, but rather an ever-changing set of empirically-derived engineering best practices, woven together by over-claiming, unreliable narratives.

https://twitter.com/fchollet/status/1333173017678028802
</textarea>
</section>

<section data-markdown>
    <textarea data-template>
## Schedule

1. _Introduction to Deep Learning_
1. Image Recognition
1. Unsupervised Deep Learning
1. Deep Reinforcement Learning

</textarea>
</section>

<section data-markdown style="font-size: xx-large;">
    <textarea data-template>
### Interactive introduction to Neural Networks with TensorFlow

_Basics of Deep Learning, derived step by step_

https://colab.research.google.com/github/DJCordhose/ml-workshop/blob/master/notebooks/intro/2021/intro-deep-learning.ipynb?hl=en


Optional I: https://colab.research.google.com/github/DJCordhose/ml-workshop/blob/master/notebooks/intro/nn-03-regularization.ipynb?hl=en

Optional II: https://colab.research.google.com/github/DJCordhose/ml-workshop/blob/master/notebooks/intro/nn-01-regression.ipynb?hl=en

</textarea>
</section>


<section data-markdown>
    <textarea data-template>

### Classification vs Regression

_Regressions predict a quantity, and classifications predict a label_

<img src="img/classification.jpg" height="400">

1. Regression: Fitting a curve (often a line) through data points
2. Classification: What category can be derived from data

</textarea>
</section>

<section data-markdown style="font-size: xx-large">
    <textarea data-template>
## Practical advice from a master of his craft

_Challenges of training neural nets_
1. Neural net training is a leaky abstraction - you need to understand what is going on
1. Neural net training fails silently - the possible error surface is large

_The recipe_
1. Understand your data
1. Make one simple experiment after the other
1. Make your model good / large enough to overfit on a batch
1. Regularize on full data set
1. Tune and scrape the barrel

<small>

https://karpathy.github.io/2019/04/25/recipe/    

</small>
</textarea>
</section>

<section data-markdown>
    <textarea data-template>
## Challenges of Deep Learning

* deep learning is more an art than a science
* we can provide guidelines as to what is likely to work or not
* ultimately every problem is unique 
* you will have to try and evaluate different strategies empirically
* currently there is no theory that will tell you in advance precisely what you should do to optimally solve a problem
* You must try and iterate

<small>

François Chollet in [Deep Learning with Python (Manning Publications)](https://www.manning.com/books/deep-learning-with-python?a_aid=keras&a_bid=76564dff)    

</small>

</textarea>
</section>

<section data-markdown>
ML researchers work with fixed benchmark datasets, and spend all of their time searching over the knobs they do control: architecture & optimization. In applied ML, you're likely to spend most of your time on data collection and annotation -- where your investment will pay off.

https://twitter.com/fchollet/status/1353421758699687942
    </section>    

<section data-markdown>
    <textarea data-template>
## Schedule

1. Introduction to Deep Learning
1. _Image Recognition_
1. Unsupervised Deep Learning
1. Deep Reinforcement Learning

</textarea>
</section>


<section data-markdown>
    <textarea data-template>
#### Even seemingly simple tasks are so far unsolved

recognizing digits and numbers in natural scene images

<img src='img/house_numbers.png' height="450px">

<small>

http://ufldl.stanford.edu/housenumbers/
</small>
    </textarea>
</section>



<section data-markdown style="font-size: xx-large;">
    <textarea data-template>
## Networks for Images

_A much more realistic example. How do you approach a challenge like this and how to you make it generalize to the real world._

https://colab.research.google.com/github/DJCordhose/ml-workshop/blob/master/notebooks/intro/2021/intro_cnn.ipynb?hl=en

Outdated version unsuccessfully trying transfer learning

https://colab.research.google.com/github/DJCordhose/ml-workshop/blob/master/notebooks/tf2/images-intro.ipynb?hl=en

(just for the idea how to do that) 
</textarea>
</section>

<section data-markdown>
    <textarea data-template>
### Understanding CNNs  

_Network to process images_

<a href='https://poloclub.github.io/cnn-explainer/'>
<img src='img/cnn-explainer.png' height="400">
</a>
<small>

https://poloclub.github.io/cnn-explainer/
</small>
</textarea>
</section>

    <section data-markdown class="hide">
### Ende von Tag 1

Rezepte heraus holen
    
    </section>    

<section data-markdown style="font-size: xx-large;">
    <textarea data-template>
### Composing Neural Networks

* input and output need to match training data and loss function
* some parts have clear function
  * mapping between dimensions, linear layer
  * Flatten, Reshape, BatchNorm, Dropout, Up-/Down-Sample
* the rest: 
  * soviet approach to aviation: add enough power until things become airborne

Oriol Vinyals - The Deep Learning toolkit in 2020:  https://youtu.be/-fdexQBpRas
</textarea>
</section>

<section data-markdown>
    <textarea data-template>
## Best Practices - Tabular data

* as a starting point
  * 2-3 hidden layers
  * 500 neurons per layer

* all hidden layers get ReLU activation
  * only change to something else if model does not train

https://lilianweng.github.io/lil-log/2019/03/14/are-deep-neural-networks-dramatically-overfitted.html
</textarea>
</section>

<section data-markdown style="font-size: xx-large;">
    <textarea data-template>
## Best Practices - Image Data

* try a couple of standard architectures 
  * ResNet 50 can be a good starting point
  * transfer learning typically does not work
    * might only work if your image data is similar to ImageNet 
  * use large batch size and SGD as a means to force regularization
    * https://twitter.com/DJCordhose/status/1376140631555371008
* if standard model seems too complex or does not generalize try custom model
  * VGG subset with dropout and Batch Normalization might be a good candidate

https://keras.io/api/applications/
https://keras.io/api/applications/resnet/#resnet50v2-function

</textarea>
</section>

<section data-markdown style="font-size: xx-large;">
    <textarea data-template>
## Losses

need to match final layer and output of training data 

* regression: linear (or any other activation if the range of values is limited) activation and MSE 
* two class: sigmoid activation and binary cross entropy
* multi class: softmax activation with categorical cross entropy
* multi-label: sigmoid activation and binary cross entropy, each output node would encode an hypothesis of its own

https://stats.stackexchange.com/questions/260505/should-i-use-a-categorical-cross-entropy-or-binary-cross-entropy-loss-for-binary
https://towardsdatascience.com/cross-entropy-for-classification-d98e7f974451

<!-- 
https://gombru.github.io/2018/05/23/cross_entropy_loss/
https://machinelearningmastery.com/how-to-choose-loss-functions-when-training-deep-learning-neural-networks/
https://towardsdatascience.com/understanding-binary-cross-entropy-log-loss-a-visual-explanation-a3ac6025181a
https://www.youtube.com/watch?v=ErfnhcEV1O8
https://towardsdatascience.com/cross-entropy-for-classification-d98e7f974451
 -->
</textarea>
</section>

<section>
    <img src='img/data.png'>
</section>

<section data-markdown>
    <textarea data-template>
## Networks for Sequences, Time Series and Texts

</textarea>
</section>

<section>
    <h3>How does this sequence continue?</h3>
    
    <pre><code contenteditable data-trim class="line-numbers python">
[10, 20, 30, 40, 50, 60, 70, 80, 90]    
        </code></pre>
    <p>Question: How do we train a network to predict the next number?</p>
</section>

<section data-markdown>
        <textarea data-template>
### Challenge: Dense Networks have no memory of previous events

They lack capability to deal with sequential data, which is required to predict time series or "understand" text
            </textarea>
            </section>

            <section data-markdown class='advanced'>
        <textarea data-template>
### Solution: Recurrent Neural Networks (RNNs)

_If training vanilla neural nets is optimization over functions, training recurrent nets is optimization over programs._

RNNs are Turing-Complete 

<small>

http://karpathy.github.io/2015/05/21/rnn-effectiveness/
<br>
http://binds.cs.umass.edu/papers/1995_Siegelmann_Science.pdf

</small>
</textarea>
            </section>


    <section data-markdown>
        <textarea data-template>
### RNNs - Networks with Loops

<img src='img/colah/RNN-rolled.png' height="450px">

<small>

http://colah.github.io/posts/2015-08-Understanding-LSTMs/
</small>
        </textarea>
    </section>
        
    <section data-markdown>
        <textarea data-template>
### Unrolling the loop

<img src='img/colah/RNN-unrolled.png'>

<small>

http://colah.github.io/posts/2015-08-Understanding-LSTMs/
</small>
        </textarea>
    </section>

        <section data-markdown>
            <textarea data-template>
### Simple RNN

<img src='img/seq/fchollet_rnn.png' height="350">

<script type="math/tex; mode=display">
output_t = activation(W input_t + U output_{t-1} + b)
</script>
    
<small>
<a href="https://livebook.manning.com/#!/book/deep-learning-with-python/chapter-6/129">
    Deep Learning with Python, Chapter 6, François Chollet, Manning            
</a>

</small>

</textarea>
</section>

<section data-markdown>
    <textarea data-template>
#### Before you get tempted, read this

<img src='img/fchollet-stock-prices.png'>
<small>

https://twitter.com/fchollet/status/1177633367472259072
</small>
        </textarea>
</section>


<section data-markdown>
    <textarea data-template>
## Schedule

1. Introduction to Deep Learning
1. Image Recognition
1. _Unsupervised Deep Learning_
1. Deep Reinforcement Learning

</textarea>
</section>

<section data-markdown>
    <textarea data-template>
### The brain might map out ideas like spaces

<img src='img/embeddings/brain-abstract-knowledge.jpg' height="450">

<small>

https://twitter.com/PhilosophyMttrs/status/1085242776688775169

</small>
</textarea>
</section>

<section data-markdown class="fragments">
    <textarea data-template>
### Autoencoders

* neural network trained in unsupervised manner
* reproduces input while going through a low-dim bottleneck
* low-dim latent representation is what you are interested in
* works on all kinds of data, e.g. image, audio, and tabular

<img src='img/unsupervised/autoencoder_schema.jpg'>


<small>

https://blog.keras.io/building-autoencoders-in-keras.html

</small>
        
</textarea>
</section>

<section data-markdown class="fragments">
    <textarea data-template>
### Why Autoencoders

* compression
* data denoising
* dimensionality reduction / clustering (for data visualization)
* building an abstract representation for further use

<small>

https://blog.keras.io/building-autoencoders-in-keras.html

</small>
        
</textarea>
</section>

<section data-markdown>
    <textarea data-template>
### Example Application: Outlier Detection

An anomaly (outlier, abnormality) is defined as “an observation which deviates so much from other observations as to
arouse suspicions that it was generated by a different mechanism” - Hawkins 1980.

https://www.springer.com/gp/book/9789401539968
</textarea>
</section>

<section data-markdown>
    <textarea data-template>
### Demo: Anomagram 
<a href='https://victordibia.github.io/anomagram/#/'>
<img src='img/embeddings/anomagram-inference.gif' height="450">
</a>
<br>
<small>

https://github.com/victordibia/anomagram        
https://victordibia.github.io/anomagram/#/
    
</small>
</textarea>
</section>

<section data-markdown class="fragments">
    <textarea data-template>
### Detecting Anomalies in electrocardiograms (ECG) 

* Train with normal data to low reconstruction loss
* Abnormal data will not be reproduced well, i.e. will have high reconstruction loss
* Set a threshold on loss by maximizing a metric (accuracy)
* Does not need abnormal data for training (but can tolerate some abnormal data)
* Can do without any labelling

</textarea>
</section>

<section data-markdown>
    <textarea data-template>
### Exercise: Train your first Autoencoder 

<a href='https://victordibia.github.io/anomagram/#/train'>
<img src='img/embeddings/anomagram-training.gif' height="450">
<br>
<small>

https://victordibia.github.io/anomagram/#/train  
</small>
</textarea>
</section>

<section data-markdown class="todo">
    <textarea data-template>
## Folien aus M3 Talk hier nach der endgültigen Version des Talks übersetzen und einfügen        
</textarea>
</section>


<section data-markdown style="font-size: xx-large;">
    <textarea data-template>
## Introduction to Autoencoders

https://colab.research.google.com/github/DJCordhose/ml-workshop/blob/master/notebooks/intro/2021/intro_autoencoder.ipynb?hl=en

Hands-On:
1. train model and tweak threhold to identify broken schreenshots

Optional:
1. experiment with dimensions of latent space, L1 and L2 regularization, and batch size and epochs
1. do the plots of the latent space make sense? 
</textarea>
</section>

<section data-markdown>
    <textarea data-template>
## What else in the area of Deep Unsupervised Learning?
### Restricted Boltzmann Machines, VAEs, and GANs        
</textarea>
</section>

<section data-markdown>
    <textarea data-template>
<img src='img/NeuralNetworkZoo20042019.png' height="600">        
<small>
https://www.asimovinstitute.org/neural-network-zoo/    
</small>        
    </textarea>
</section>

<section data-markdown>
    <textarea data-template>
### Restricted Boltzmann Machines (RBMs)

* RBMs were founded 1986 by Geoffrey Hinton
* Two-Layer networks like half an autoencoder where data flows back and forth
* interesting for historical reasons, but surpassed by more up-to-date models: AE, VAE, GANS
* Embeddings/Latent Space/Hidden Representation originally called 'Distributed representations'

<small>

https://en.wikipedia.org/wiki/Boltzmann_machine    
https://dl.acm.org/citation.cfm?id=104287
<br>
http://www.cs.toronto.edu/~hinton/absps/families.pdf
<br>
https://pathmind.com/wiki/restricted-boltzmann-machine
<br>
https://towardsdatascience.com/restricted-boltzmann-machines-simplified-eab1e5878976

</small>
</textarea>
</section>

<section data-markdown class="fragments">
    <textarea data-template>
### Variational Auto Encoders (VAE)

* VAE is a generative model
* latent space learns a probability distribution modelling your data
* actually learning mean and standard deviation of distribution
* sampling from it can generate new data

<small>

https://blog.keras.io/building-autoencoders-in-keras.html
<br>
https://colab.research.google.com/github/DJCordhose/ml-workshop/blob/master/notebooks/tf2/autoencoder-mnist-vae-gan.ipynb
https://github.com/keras-team/keras/blob/master/examples/variational_autoencoder.py

</small>
</textarea>
</section>

<section data-markdown>
    <textarea data-template>
### VAE illustrated

<img src='img/unsupervised/vae.png' height="500px">

<small>

https://towardsdatascience.com/intuitively-understanding-variational-autoencoders-1bfe67eb5daf
</small>

</textarea>
</section>

<section>
<h3>Generating Celebreties</h3>
<p>Trained for two weeks on a single high-end GPU on CelebA-HQ data set (images of celebreties)</p>
<div class="fragment" style="float: left">
<img src="img/unsupervised/gan-model-male2.png" height="220">
</div>
<div class="fragment" style="float: left; padding-left: 25px">
    <img src="img/unsupervised/gan-model-female2.png" height="220">
</div>
<div class="fragment" style="float: left; padding-left: 25px">
    <img src="img/unsupervised/gan-model-female1.png" height="220">
</div>
<div class="fragment" style="float: left; padding-left: 25px">
    <img src="img/unsupervised/gan-model-male.png" height="220">
</div>
<p style="clear: both">
<small>
<a href="https://alantian.net/ganshowcase/" target="_blank">https://alantian.net/ganshowcase/</a>
<br>
<a href="https://github.com/alantian/ganshowcase" target="_blank">https://github.com/alantian/ganshowcase</a>
<br>
<a href="https://twitter.com/alanyttian/status/988242167998148608" target="_blank">https://twitter.com/alanyttian/status/988242167998148608</a>
</small>
               
</p>
</section>                                

<section data-markdown>
<textarea data-template>
## GANs

* Generative adversarial networks
* uses two neural networks, working against the each other
*  one network tries to create artefacts that look real
* the other one tries to classify which artefact presented is real and which is fake 
* typically superior to VAE

<small>

https://pathmind.com/wiki/generative-adversarial-network-gan

https://arxiv.org/abs/1406.2661

</small>

</textarea>
</section>

<section data-markdown>
<textarea data-template>
### Understanding GANs

<a href='https://poloclub.github.io/ganlab/'>
<img src='img/unsupervised/gan-lab.png'>
</a>
    
<small>

https://twitter.com/minsukkahng/status/1037016214575505409
https://poloclub.github.io/ganlab/
https://minsuk.com/research/papers/kahng-ganlab-vast2018.pdf

</small>
</textarea>
</section>



<section data-markdown>
    <textarea data-template>
## Schedule

1. Introduction to Deep Learning
1. Image Recognition
1. Unsupervised Deep Learning
1. _Deep Reinforcement Learning_

</textarea>
</section>

<section data-markdown class="fragments">
### Reinforcement Learning

* special position in the field of machine learning
* does not rely on existing data here
* generates data in experiments
* experiments conducted in simulation or in the real world, if safel and in large numbers
* experiments depend on desired outcome
* desired outcome which formally defined by rewards
* corresponds most closely to what many people intuitively imagine as intelligent behavior: learning more or less independently based on experience

</section>    

<section data-markdown class="fragments">
### State of Reinforcement Learning

* still rather academic
* computer or board typical academic application
* algorithm is central and important for academics
* practical applications include 
  * optimization
  * robotics
  * multi-armed bandits as a more general form of A/B testing
</section>    

<section data-markdown>
<textarea data-template>
### Real challenge is to model the problem for RL

<div  style="max-width: 45%; float: left">
<br>
<img src='img/rl2/rl.png'>
</div>
<div style="max-width: 50%; float: right">
<br>
<ol>
    <li>Based on <em>Observations</em> an <em>Agent</em> executes </li>
<li> <em>Actions</em> within a given  
<li><em>Environment</em> which lead to positive or negative 
<li><em>Rewards</em>.
</ol>
</div>

<div style="clear: both;">
    <br>
    <p >The Agent’s job is to maximize the cumulative Reward</p>
</div>

http://gym.openai.com/docs/

</textarea>
</section>

<section data-markdown>
    <textarea data-template>
### Our Application

<img src='img/rl2/orso.png' height="500">

</textarea>
</section>

<section data-markdown class="fragments">
    <textarea data-template>
### Shared Exercise: How to model as an RL problem?

- Objective: What should be achieved? When is an episode over?
- Environment: Who or what provides observations and rewards? Typically a simulation or the real world.
- Actions: What are the possible actions of the agent?
- Agent: Who or what chooses actions?
- Observations: What does the environment indicate to the agent?
- Rewards: What are the rewards and how much are they?

</textarea>
</section>

<section data-markdown>
    <textarea data-template>
### Sample/Reference Solution: Objective

* find the least strenuous way through the territory
* eat all the honey 
* finally get back to the cave
* after a certain number of steps we abort the episode without success
</textarea>
</section>

<section data-markdown>
    <textarea data-template>
### Sample/Reference Solution: Environment

Software simulation of the bear's territory
</textarea>
</section>

<section data-markdown class="fragments">
    <textarea data-template>
### Sample/Reference Solution: Actions

* 4 discrete actions in the style of an Atari game:
  * left
  * right
  * up
  * down
* doing nothing is not an option
  * the bear never learns that staying in the cave and just sleeping on might be an interesting solution to the problem
</textarea>
</section>

<section data-markdown>
    <textarea data-template>
### Sample/Reference Solution: Agent: 

The bear
* how this looks like technically we have to discuss later
</textarea>
</section>

<section data-markdown class="fragments">
    <textarea data-template>
### Sample/Reference Solution: Observations

* we show the bear only the part of its territory that it can see from its current position (partially observed)
* such an observation makes the problem more challenging
* just as we would have to explore the game situation in such a game, the bear would have to do the same in many playthroughs
* we choose this variant to demonstrate the power of reinforcement learning

_More details in Notebook_

</textarea>
</section>

<section data-markdown class="fragments">
    <textarea data-template>
### Sample/Reference Solution: Rewards

* for each step we combine different rewards 
* normalize them by the theoretical number of points to be achieved
* namely the sum of the rewards of all honey pots.
* reward always below 1
* if it is negative there was only cost, no reward.
* different costs per path are modeled
* honey is attractive to collect even if the path is expensive
* otherwise the incentive for the bear is not there

</textarea>
</section>


<section data-markdown>
    <textarea data-template>
### There are a lot of algorithms

<img src='img/rl_algorithms_9_15.svg'>
<small>

https://spinningup.openai.com/en/latest/spinningup/rl_intro2.html    

</small>

</textarea>
</section>

<section data-markdown>
    <textarea data-template>
### For practical work PPO is the algorithm to choose when creating samples is inexpensive

* if samples are expensive SAC might be best choice
* for our example sampling is cheap

https://spinningup.openai.com/en/latest/algorithms/ppo.html

</textarea>
</section>    


<section data-markdown>
    <textarea data-template>
### PPO (Proximal Policy Optimization)

<img src='img/rl2/ppo.png'>

</textarea>
</section>    

<section data-markdown>
    <textarea data-template>
### Deep Reinforcement Learning with PPO

<img src='img/rl2/drl-ppo.png'>

<small><em>
PPO uses two networks
</em></small>
    
</textarea>
</section>

<section data-markdown>
    <textarea data-template>
### Special Loss in PPO

* most advanced and practical variant of policy gradient branch
* uses vanilla backpropagation for training
* has special loss consisting of many parts
* turns hard constraints into penalties 
* uses value function to have better generalization

<small><em>
More details in Notebook
</em></small>
    
</textarea>
</section>

<section data-markdown>
    <textarea data-template>
### Policy Loss

_which action to perform_

<img src='img/rl2/policy_loss.png' height="500">

<small><em>
</em></small>
    
</textarea>
</section>

<section data-markdown>
    <textarea data-template>
### Value Loss

_prediction of reward_

<img src='img/rl2/value_loss.png' height="500">

</textarea>
</section>

<section data-markdown>
    <textarea data-template>
### KL Loss

_prevent catatrophic updates_
    
<img src='img/rl2/kl_loss.png' height="500">

    
</textarea>
</section>

<section data-markdown>
    <textarea data-template>
### Entropy Loss

_trade exploitation for exploration over time_

<img src='img/rl2/entropy_loss.png' height="500">

</textarea>
</section>

<section data-markdown style="font-size: xx-large;">
    <textarea data-template>
## Introduction to Deep Reinforcement Learning

https://colab.research.google.com/github/DJCordhose/ml-workshop/blob/master/notebooks/intro/2021/intro_rl.ipynb?hl=en

</textarea>
</section>

<section data-markdown>
        <textarea data-template>
# Finally
    
</textarea>
</section>

<section data-markdown>
    <textarea data-template>
#### You can describe all networks as a combination of encoder / decoder

<img src='img/embeddings/encoder-decoder-everywhere.png' height="530">

<small style="font-size: large">

https://medium.com/tensorflow/mit-deep-learning-basics-introduction-and-overview-with-tensorflow-355bcd26baf0
</small>
    </textarea>
</section>


<section data-markdown style="font-size: xx-large;">
    <textarea data-template>
## Teaching Resources by Keras author François Chollet

* https://keras.io/getting_started/
* A list of up-to-date Keras examples in one place: https://keras.io/examples/
* A list of in-depth guides to learn modern Keras: https://keras.io/guides/

<!-- * Intro to Keras for Researchers: https://colab.research.google.com/drive/169PfzM0kvtA5UP4k6Sl1yCG9tsE2MLia
* Intro to Keras for Engineers: https://colab.research.google.com/drive/1lWUGZarlbORaHYUZlF9muCgpPl8pEvve
* Image classification from scratch: https://colab.research.google.com/drive/1umJnCp8tZ7UDTYSQsuWdKRhqbHts38AC
* Deep Dream:  https://colab.research.google.com/drive/18XPdEDVYdr_ODAvW0DrWRCRC25tvTuCE
* Activation Maps:  https://colab.research.google.com/drive/1CJQSVaXG1ceBQGFrTHnt-pt1xjO4KFDe
* Transfer Learning:  https://colab.research.google.com/drive/17vHSAj7no7RMdJ18MJomTf8twqw1suYC
* VAE:  https://colab.research.google.com/drive/1COeSoasrpY-w3uF1JPVksLEjx4Tx2ns5 -->

                            </textarea>
    </section>

<section data-markdown style="font-size: xx-large;">
    <textarea data-template>
## More Teaching Resources

* https://www.tensorflow.org/guide
* https://github.com/parrt/fundamentals-of-deep-learning
* Short and practical introduction to data science: https://github.com/rasbt/data-science-tutorial
* Fundamentals of Machine Learning and Deep Learning in Python using Scikit-Learn, Keras and TensorFlow 2: https://github.com/ageron/handson-ml2
* CS231n: Convolutional Neural Networks for Visual Recognition: http://cs231n.stanford.edu/
* CS224n: Natural Language Processing with Deep Learning: http://web.stanford.edu/class/cs224n/index.html#schedule


</textarea>
    </section>

<section data-markdown  style="font-size: x-large;">
    <textarea data-template>
## All Notebooks

* Intro/Classification: https://colab.research.google.com/github/DJCordhose/ml-workshop/blob/master/notebooks/intro/2021/intro-deep-learning.ipynb?hl=en
  * Generalization: https://colab.research.google.com/github/DJCordhose/ml-workshop/blob/master/notebooks/intro/nn-03-regularization.ipynb?hl=en

* Image/CNN: https://colab.research.google.com/github/DJCordhose/ml-workshop/blob/master/notebooks/intro/2021/intro_cnn.ipynb?hl=en
  * Outdated version unsuccessfully trying transfer learning (just for the idea how to do that): https://colab.research.google.com/github/DJCordhose/ml-workshop/blob/master/notebooks/tf2/images-intro.ipynb?hl=en

* Autoencoder/Unsupervised: https://colab.research.google.com/github/DJCordhose/ml-workshop/blob/master/notebooks/intro/2021/intro_autoencoder.ipynb?hl=en
  
* Deep Reinforcement Learning: https://colab.research.google.com/github/DJCordhose/ml-workshop/blob/master/notebooks/intro/2021/intro_rl.ipynb?hl=en
</textarea>
</section>




         <!-- <section data-markdown style="font-size: xx-large;">
            <textarea data-template>
### Finding data sets to play with
    
* Google released a search engine for datasets
  * Search: https://toolbox.google.com/datasetsearch
  * Launch blog post: https://www.blog.google/products/search/making-it-easier-discover-datasets/
* Kaggle Datasets: https://www.kaggle.com/datasets
* TensorFlow Datasets: https://medium.com/tensorflow/introducing-tensorflow-datasets-c7f01f7e19f3
* https://www.openml.org/search?type=data
* https://github.com/jbrownlee/Datasets
</textarea>
</section> -->

        </div>
    </div>

    <script src="reveal.js/js/reveal.js"></script>
    <script src="lib/jquery-2.2.4.js"></script>
    
    <script>
            // $('section:not([data-background])').attr('data-background', "background/white.jpg");
            // $('section:not([data-background])').attr('data-background', "background/pale-clouds.jpg");
            // $('section:not([data-background])').attr('data-background', "background/street.jpg");
            // $('section:not([data-background])').attr('data-background', "background/white-transparent.jpg");
    </script>
    
    <script>
            const isLocal = window.location.hostname.indexOf('localhost') !== -1 || 
                        window.location.hostname.indexOf('127.0.0.1') !== -1;
    
            $('.hide').remove();
    
            if (isLocal && !printMode) {
            } else {
                // only applies to public version
                    $('.todo').remove();
                    $('.preparation').remove();
                    $('.local').remove();
            }
        
            Reveal.addEventListener( 'ready', function( event ) {
                // applies to all versions
                $('code').addClass('line-numbers');
        
                $('.fragments li').addClass('fragment')
        
                // make all links open in new tab
                $('a').attr('target', '_blank')
        
                if (isLocal && !printMode) {
                    // only applies to presentation version
                    Reveal.configure({ controls: false });
                } else {
                    // only applies to public version
                    // $('.fragment').removeClass('fragment');
                }
    
                // we do not like fragments
                // $('.fragment').removeClass('fragment');
    
            } );
    
    </script>
        
    <script>
    
        // Full list of configuration options available at:
        // https://github.com/hakimel/reveal.js#configuration
        Reveal.initialize({
            controls: true,
            progress: true,
            history: true,
            center: true,
            width: 1100,
            slideNumber: true,
    
            transition: 'fade', // none/fade/slide/convex/concave/zoom
    
            math: {
                 mathjax: 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js',
                config: 'TeX-AMS_HTML-full'  // See http://docs.mathjax.org/en/latest/config-files.html
            },
    
            // Optional reveal.js plugins
            dependencies: [
                {
                    src: 'reveal.js/lib/js/classList.js', condition: function () {
                    return !document.body.classList;
                }
                },
                {
                    src: 'reveal.js/plugin/markdown/marked.js', condition: function () {
                    return !!document.querySelector('[data-markdown]');
                }
                },
                {
                    src: 'reveal.js/plugin/markdown/markdown.js', condition: function () {
                    return !!document.querySelector('[data-markdown]');
                }
                },
                {
                    src: 'reveal.js/plugin/highlight/highlight.js', async: true, condition: function () {
                    return !!document.querySelector('pre code');
                }, callback: function () {
                    hljs.initHighlightingOnLoad();
                }
                },
                {src: 'reveal.js/plugin/zoom-js/zoom.js', async: true},
                {src: 'reveal.js/plugin/notes/notes.js', async: true},
                // https://github.com/mikemiles86/reveal-line-numbers
                {src: 'lib/js/line-numbers.js'},
                { src: 'reveal.js/plugin/math/math.js', async: true }
    
            ]
        });
    
    </script>
    
    </body>
    </html>
    