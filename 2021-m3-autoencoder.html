<!doctype html>
<html lang="de">

<head>
    <meta charset="utf-8">

    <title>M3 2021: Visuelle Regressionstests mit Autoencodern</title>

    <meta name="description" content="M3 2021: Visuelle Regressionstests mit Autoencodern">
    <meta name="author" content="Oliver Zeigermann">
	<link rel="shortcut icon" href="/img/favicon.ico" >

    <meta name="apple-mobile-web-app-capable" content="yes"/>
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent"/>

    <meta name="viewport"
          content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, minimal-ui">

          <link rel="stylesheet" href="reveal.js/css/reveal.css">
          <link rel="stylesheet" href="reveal.js/css/theme/white.css" id="theme">
          <!--<link rel="stylesheet" href="reveal.js/css/theme/black.css" id="theme">-->
          <!--<link rel="stylesheet" href="reveal.js/css/theme/night.css" id="theme">-->
          <!--<link rel="stylesheet" href="reveal.js/css/theme/simple.css" id="theme">-->
          <!-- <link rel="stylesheet" href="reveal.js/css/theme/solarized.css" id="theme"> -->
      
          <link href="https://fonts.googleapis.com/css?family=Work+Sans:400,700" rel="stylesheet">

            <!-- Theme used for syntax highlighting of code -->
            <link rel="stylesheet" href="reveal.js/lib/css/monokai.css">
          <style>
              /*pre code {*/
                  /*display: block;*/
                  /*padding: 0.5em;*/
                  /*background: #FFFFFF !important;*/
                  /*color: #000000 !important;*/
              /*}*/
      
            @font-face {
                font-family: Sunrise;
                src: url("Sunrise International_special.ttf") format("opentype");
            }

              .right-img {
                  margin-left: 10px !important;
                  float: right;
                  height: 500px;
              }
              .todo:before {
                  content: 'TODO: ';
              }
              .todo {
                  color: red !important;
              }
              code span.line-number {
                  color: lightcoral;
              }
              .reveal pre code {
                  max-height: 1000px !important;
              }
      
              img {
                  border: 0 !important;
                  box-shadow:0 0 0 0 !important;
                  height: 450px;
              }
      
              .reveal {
                  -ms-touch-action: auto !important;
                  touch-action: auto !important;
                      }

                .reveal h1,
                .reveal h2,
                .reveal h3,
                .reveal h4  {
                        /* letter-spacing: 2px; */
                        font-family: 'Calibri', sans-serif;
                          /* font-family: 'Times New Roman', Times, serif; */
                          /* font-weight: bold; */
                          color: black;
                          /* font-style: italic; */
                          /* letter-spacing: -2px; */
                          text-transform: none !important;
                      }
      
                      .reveal em {
                          font-weight: bold;
                      }
      
              .reveal section img {
                background: none;
              }
      
                      .reveal img.with-border {
                          border: 1px solid #586e75 !important;
                          box-shadow: 3px 3px 1px rgba(0, 0, 0, 0.15) !important;
                      }
      
                      .reveal li {
                          margin-bottom: 8px;
                      }
      
                      /* For li's that use FontAwesome icons as bullet-point */
                  .reveal ul.fa-ul li {
                      list-style-type: none;
                  }

            .reveal {
                /* font-family: 'Work Sans', 'Calibri'; */
                font-family: 'Calibri';
                color: black !important;
                font-size: xx-large;
             }

          </style>
      
    <!-- Printing and PDF exports -->
    <script>
        var link = document.createElement('link');
        link.rel = 'stylesheet';
        link.type = 'text/css';
        var printMode = window.location.search.match(/print-pdf/gi);
        link.href = printMode ? 'reveal.js/css/print/pdf.css' : 'reveal.js/css/print/paper.css';
        document.getElementsByTagName('head')[0].appendChild(link);
    </script>

    <!--[if lt IE 9]>
    <script src="reveal.js/lib/js/html5shiv.js"></script>
    <![endif]-->
</head>

<body style="background-color: whitesmoke;">

<div class="reveal">
    <div class="slides">

 <section data-markdown class="preparation">
    <textarea data-template>
### Starten        

* https://www.mentimeter.com/s/1f84385b85154e069317d4a39ea83fa7/e230a5bf994b/edit
* https://www.mentimeter.com/s/14af7c432a37f0c78cf1d45663c7198f/30244b69d3bb/edit        
    </textarea>
</section>

<!-- 


Titel: Visuelle Regressionstests mit Autoencodern
Art des Vortrags: Vortrag (45 Minuten)
Niveau: Grundlagen

Abstract:
Das Aussehen und die Bedienbarkeit von Webanwendungen ist mit klassischen Testverfahren nur schwer testbar. Lediglich
Visuelle Regressionstests überprüfen eine Anwendung gegen einen Goldmaster und können so Veränderungen gegenüber diesem
aufspüren.

Dieser Ansatz ist allerdings wenig flexibel, und natürliche Variationen in der Darstellung können nur schwer als solche
erkannte werden.

In diesem Vortrag zeige ich einen auf Autoencodern basierenden Ansatz, der einem Machine-Learning-Modell beibringt, wie
eine "normale" Anwendung aussieht und anhand dessen Abweichungen dazu feststellt.

Vorkenntnisse | Previous knowledge:
%

Lernziele | learning objectives:
Wie können mit Hilfe von Unsupervised Learning Fehler in Bildern erkannt werden?

https://www.m3-konferenz.de/lecture_compact1.php?id=12674

-->


<!-- <section data-markdown class="preparation">  
</section> -->
    
<!-- <section data-markdown class="todo">
Referenzen und mehr Links

- Enthält auch Erklärung für allgemeinen Autoencoder: https://towardsdatascience.com/made-masked-autoencoder-for-distribution-estimation-fc95aaca8467
- DALL-E scheint auch VAE zu nutzen: https://twitter.com/poolio/status/1364756787769958401
- https://learning.oreilly.com/library/view/hands-on-unsupervised-learning/9781492035633/titlepage01.html#
- Allgemeine Intro Autoencoder
  - [ ] Autoencoder als Ausnahme von Dimensionality reduction: https://youtu.be/9iol3Lk6kyU
  - [ ] Interaktiver LDA Exporer: https://omarshehata.github.io/lda-explorable/
</section> -->


<!-- <section data-markdown class="todo">
### TODO

</section> -->

<section data-markdown>
    <textarea data-template>
# Visuelle Regressionstests mit Autoencodern

M3 2021 online, https://www.m3-konferenz.de/lecture.php?id=12674

Oliver Zeigermann (<a href='https://twitter.com/djcordhose'>@DJCordhose</a>)

Diese Folien: https://bit.ly/m3-autoencoder
</textarea>
</section>

<section data-markdown>
## Welche Arten von Tests kennt ihr?

https://www.menti.com/qhxi158h8f
</section>
        
    
<section data-markdown>
### Programm

1. Visuelle Regressionstests
1. Autoencoder
1. Visuelle Regressionstests mit Autoencodern (Hauptteil)
1. Ist das schon das Ende und was kann man damit noch machen?
</section>

<section data-markdown>
### Programm

1. _Visuelle Regressionstests_
1. Autoencoder
1. Visuelle Regressionstests mit Autoencodern
1. Ist das schon das Ende und was kann man damit noch machen?
</section>


<section data-markdown>
<textarea data-template>
### Unsere Beispielanwendung

<img src='img/autoencoder/ML_0801_app.png'>

Simpel, aber komplex genug, um typische Fehlerfälle zu zeigen
</textarea>
</section>

<section data-markdown>
<textarea data-template>
### Regressionstest

_Unter einem Regressionstest (von lateinisch regredior, regressus sum ‚zurückschreiten‘) versteht man in der Softwaretechnik die Wiederholung von Testfällen, um sicherzustellen, dass Modifikationen in bereits getesteten Teilen der Software keine neuen Fehler („Regressionen“) verursachen. Solche Modifikationen entstehen regelmäßig z. B. aufgrund der Pflege, Änderung und Korrektur von Software. Der Regressionstest gehört zu den dynamischen Testtechniken._

https://de.wikipedia.org/wiki/Regressionstest    

</textarea>
</section>


<section data-markdown>
    <textarea data-template>
### Klassische Visuelle Regressionstests

<img src='img/autoencoder/compare.png'>

Vergleich von bekannt richtiger Darstellung
</textarea>
</section>
    
<section data-markdown>
    <textarea data-template>
### Klassische Visuelle Regressionstests

<img src='img/autoencoder/report.png' style="height: 100%;">

Automatischer Vergleich schlägt ab bestimmtem Schwellwert fehl
</textarea>
</section>

<section data-markdown class="fragments">
### Taugt das?

*Ja, weil es auf der Ebene testet, die auch der Benutzer sieht, aber*

* man muss für jeden Fall eine Ground-Truth erzeugen und pflegen
* viele false positives: Es gibt eine ganze Reihe von Abweichungen, die offensichtlich keine Fehler sind  
* ein generelles, intelligentes Verständnis von einer heilen Anwendung existiert nicht
</section>

<section data-markdown>
<textarea data-template>
### Problemfall 1: i18n

Neue Texte sollten nicht zum Fehlschlag führen, aber das hier schon

<img src='img/autoencoder/ML_0802_bug_i18n.png'>

Unschön, gefährdet aber nicht zwingend die Bedienbarkeit der Anwendung
</textarea>
</section>

<section data-markdown>
<textarea data-template>
### Problemfall 2: Böse Overflows

Der Knopf ist noch da, aber unsichtbar

<img src='img/autoencoder/ML_0803_bug_overflow.png'>

Passiert nur bei sehr speziellen Eingaben, macht die Anwendung aber unbedienbar
</textarea>
</section>

<section data-markdown class="fragments">
### Und nun?

* Problemfall 1 sollte kein Fehler sein, wenn der Text innerhalb der Box ist, wenn außerhalb, dann schon
* Das provozieren von Problemfall 2 ist nur durch chaotisches Testen mit Zufallsaktionen oder mit viel Erfahrung möglich
* ein generelles, intelligentes Verständnis von einer heilen Anwendung hilft in beiden Fällen
</section>

<section data-markdown>
### Programm

1. Visuelle Regressionstests
1. _Autoencoder_
1. Visuelle Regressionstests mit Autoencodern
1. Ist das schon das Ende und was kann man damit noch machen?
</section>

<section data-markdown>
    <textarea data-template>

### Autoencoder Steckbrief

* Daten
  * Eingabe: <span class="fragment" style="font-weight: bold;">Alles Arten von Daten sind möglich</span> 
  * Ausgabe: <span class="fragment" style="font-weight: bold;">Dieselben Daten</span>
* Lern-Art: <span class="fragment" style="font-weight: bold;">Unüberwacht</span>  
* Modell-Architektur: <span class="fragment" style="font-weight: bold;">Neuronales Netzwerk, symmetrisch mit Engpass</span>
* Loss: <span class="fragment" style="font-weight: bold;">Typischerweise MSE, alle NN Losses möglich</span>
* Optimierungs-Methode: <span class="fragment" style="font-weight: bold;">Backpropagation</span>
* Geschäfts-Metrik: <span class="fragment" style="font-weight: bold;">Divers und schwierig anzugeben, später mehr</span>
</textarea>

</section>

<section data-markdown class="fragments">
    <textarea data-template>
### Autoencoder

* neuronales Netz, das unüberwacht trainiert wird
* reproduziert die Eingabe, während es einen Engpass durchläuft
* Engpass ist eine Abstraktion der Daten
* nur Engpass als Hidden Layer und MSE als Loss liefert Hauptkomponenten
* arbeitet auf allen Arten von Daten, z. B. Bild-, Audio- und Tabellendaten

<img src='img/unsupervised/autoencoder_schema.jpg' style="height: 100%;">


<small>

https://blog.keras.io/building-autoencoders-in-keras.html

</small>
        
</textarea>
</section>

<section data-markdown class="fragments">
    <textarea data-template>
### Warum Autoencoder?

_Aus dem gewünschten Nutzen leitet sich die Geschäfts-Metrik ab_

* Kompression
* Datenentrauschung
* Dimensionalitätsreduktion
* Aufbau einer abstrakten Darstellung zur weiteren Verwendung
* Clustering (auch zur Datenvisualisierung)
* Ausreißer-Erkennung

</textarea>
</section>


<section data-markdown class="fragments">
    <textarea data-template>
### Autoencoder sind besonders

* Dimensionalitätsreduktion fallen sonst in die beiden Bereiche
  * Matrix-Faktorisierung oder
  * Nachbarschafts-Graphen 
* Linearer Autoencoder ist im wesentlichen PCA  
* Nicht-Lineare Autoencoder sind viel mächtiger und fallen aus allen Kategorien  

A Bluffer's Guide to Dimension Reduction - Leland McInnes: https://youtu.be/9iol3Lk6kyU?t=106

</textarea>
</section>


<section data-markdown>
    <textarea data-template>
### Anomagram, interaktives Beispiel für Unsupervised Error Detection
<a href='https://victordibia.github.io/anomagram/#/'>
<img src='img/embeddings/anomagram-inference.gif' height="450">
</a>
<br>
<small>

https://github.com/victordibia/anomagram        
https://victordibia.github.io/anomagram/#/
    
</small>
</textarea>
</section>


<section data-markdown class="fragment">
    <textarea data-template>
### Was würdest du lieber?

1. Jemandem eine Herzanomalie attestieren, der keine hat
1. Eine tatsächliche Herz-Anomalie übersehen
        
(nichts davon geht leider nicht)
    </textarea>
</section>


<section data-markdown style="font-size: xx-large">
    <textarea data-template>
### Referenz: Metrics

* _Genauigkeit (Precision)_: Prozentsatz der positiven Vorhersagen, die korrekt sind
* _Trefferquote (Recall)_: Anteil der tatsächlich positiven Vorhersagen, die richtig vorhergesagt wurden
* In einem binären Klassifikator wird oft durch einen Schwellwert zwischen positivem und negativem Ergebnis unterschieden
* Ein ausreichend niedriger Schwellenwert führt zu einem exzellenten Recall, aber zu einer reduzierten Precision
* _F1-Score_: harmonische Mittel aus Precision und Recall
        
<small>
https://de.wikipedia.org/wiki/Beurteilung_eines_bin%C3%A4ren_Klassifikators
</small>
</textarea>
</section>


<section data-markdown>
### Programm

1. Visuelle Regressionstests
1. Autoencoder
1. _Visuelle Regressionstests mit Autoencodern_
1. Ist das schon das Ende und was kann man damit noch machen?
</section>

<section data-markdown>
<textarea data-template>
### Was wir eher wollen

Sieht die Anwendung ungewöhnlich aus?

<img src='img/autoencoder/ML_0808_test_diff.png'>

Sehr lange Zahlen und komische Box oben rechts
</textarea>
</section>


<section data-markdown>
<textarea data-template>
### Wir vergleichen die Darstellung mit der erwarteten

Fehlerfreie Darstellung im Vergleich

<img src='img/autoencoder/ML_0807_train_diff.png'>

Viel näher an der Erwartung
</textarea>
</section>

<section data-markdown class="fragments">
### Zusammenfassung Ansatz  

_Wir vergleichen beliebige Darstellung mit der als heil erwarteten_

* dann vergleichen wir wie sehr sich diese unterscheiden
* ab einer gewissen Grenze gehen wir davon aus, dass diese fehlerhaft sein könnte
* nur dann muss der Mensch vergleichen
* ein Anlegen und die Wartung von Ground-Truths ist nicht mehr notwendig
</section>

<section data-markdown>
## Schwierigkeit

### Woher bekommen wir für jede beliebige Darstellung die als heil erwartete?
</section>

<section data-markdown>
    <textarea data-template>
### Unser Autoencoder als Lösung

* Eingabe und Ausgabe: <span class="fragment" style="font-weight: bold;">Screenshots unserer Anwendung 256x256 als Graustufen von 0-1</span>
* Modell-Architektur: <span class="fragment" style="font-weight: bold;">Stacked Convolutional für Encoder, Deconvolutional für Decoder, 8 Neuronen im Engpass</span>
* Geschäfts-Metrik: <span class="fragment" style="font-weight: bold;">Anzahl passender Pixel gerundet auf Schwarz (0) oder Weiß (1)</span>
* Loss: <span class="fragment" style="font-weight: bold;">Nicht MSE, weil Problem speziell formuliert ist, sondern Binary Cross-Entropy</span>

<img src='img/unsupervised/autoencoder_schema.jpg' style="height: 100%;">

</textarea>

</section>

<section data-markdown>
<textarea data-template>
### Encoder

<img src='img/autoencoder/ML_0804_encoder.png'>

</textarea>
</section>

<section data-markdown class="fragments">
<textarea data-template>
### Encoder Details

1. Bilder haben eine Auflösung von 256x256 und einen einzigen Farbkanal
2. n Blöcken, die die Auflösung des Bilds mit jeder Convolution halbieren 
   * MaxPooling Layer reduziert nach jeder Convolution nochmals die Auflösung 
3. fasst die 16 Filter-Eingaben des vorherigen Layers in einer einzigen Ausgabe zusammen
  * erlaubt aber eine weitere Messpunkt für eine menschlich verständliche Ausgabe
4. 8x8 Bilder mit Graustufen flach geklopft als Eingabe für den Flaschenhals
5. Dimensionierung des Flaschenhalses ist 8 und unterliegt unserer Willkür
</textarea>
</section>


<section data-markdown>
<textarea data-template>
### Decoder

<img src='img/autoencoder/ML_0805_decoder.png'>

</textarea>
</section>


<section data-markdown class="fragments">
<textarea data-template>
### Decoder Details

1. Ausgabe des Encoders ist ein flacher Vektor mit 8 Werten
  * Wir machen daraus 8 Bilder mit einem Pixel als Auflösung
2. Conv2DTranspose und UpSampling2D Umkehrung der Convolution und des Downsamplings
  * Von dieser Kombination schalten wir so viele Blöcke hintereinander wie wir brauchen, um die ursprüngliche Auflösung des Bilds wieder zu erlangen
  * Gegenläufig zum Encoder steigen dabei Anzahl der Filter
3. Fasst alle 64 vorheringen Kanäle zu einem einzigen Kanal zusammen
  * Komprimiert den Wertraum mit einem Sigmoid auf den Bereich zwischen 0 und 1 als Grauwert ausgegeben
</textarea>
</section>

<section data-markdown>
<textarea data-template>
### Sehr kleiner Engpass erzwingt extreme Abstraktion

Ergebnis von Stacked Convolutional Layers direkt vor Engpass  

<img src='img/autoencoder/ML_0811_h.png'>

</textarea>
</section>

<section data-markdown>
<textarea data-template>
### Der Engpass...`

* hat nur 8 Werte
* ist viel kleiner als die Eingabe, d.h. der Autoencoder ist extrem "undercomplete"
* hat eine Lineare Aktivierung
* wird nicht durch L1-Regularisierung Sparse gemacht, d.h. Werte im Engpass sind nicht 0
* wird auch nicht L2 Regularisiert
</textarea>
</section>

<section data-markdown class="fragments">
### Wie läuft das Training?

* Trainingsdaten sind Golden Master des aktuell als korrekt bekannten Releases
  * wir gehen davon aus, dass die Anwendung vor der Änderung größtenteils wie erwartet aussah
* Test- und Validation sind der Golden Master des neuen Release-Kandidation
* Der Autoencoder lernt also wie die Anwendung normalerweise aussehen sollte
</section>

<section data-markdown class="fragments">
### Was nicht im Paper stehe würde
    
* Ohne die erwähnte Umformulierung des Problems und den Binary Cross-Entropy Loss läuft gar nichts
* Kudos dafür an Aurélien Géron und https://learning.oreilly.com/library/view/hands-on-machine-learning/9781491962282/
* ein paar andere kleine Trial-and-Error-Fummeleien ohne die es bei DL scheinbar nie geht
    </section>
    
    
<section data-markdown>
<textarea data-template>
### Trainingsverlauf

Das Modell lernt sehr gut wie die Anwendung aussehen sollte (Blau)

<img src='img/autoencoder/ML_0806_acc.png'>

Das neue Release zeigt deutliche Abweichungen (Orange)
</textarea>
</section>


<section data-markdown>
<textarea data-template>
### Wie gut funktioniert das Training

Für die als richtig bekannten Screenshots

<img src='img/autoencoder/ML_0809_train_acc_hist.png'>

Links sieht man ungewöhnliches, vielleicht sogar kaputtes
</textarea>
</section>

<section data-markdown>
<textarea data-template>
## Wie setzt man den Schwellwert?

* Wir haben keine Labels (Ground-Truth), können daher nicht Sensitivität und Spezifität berechnen
* Wir machen daher Annahmen
  1. Normalverteilung der Accuracy oder MSE
  1. Entweder die Screenshots des neuen Releases als hauptsächlich falsch oder korrekt 
  1. Alle mit mehr als 3 Standardabweichugnen als Fehlerhaft ansehen 
* Als Mensch kann man das interaktiv einfacher
  * Teils durch Intuition, meist durch ausprobieren (wir sehen an einem Bild, ob es einen Fehler enthält)
  * Heuristik: Threshold komplett rechts von allen Traningsdaten
</textarea>
</section>


<section data-markdown>
<textarea data-template>
### Autoencoder angewandt auf das neue Release

Der Schwellwert *0.985* ist willkürlich gesetzt, wir nehmen hauptsächlich falsch an 

<img src='img/autoencoder/ML_0810_test_acc_hist.png'>

Screenshots links des Schwellwerts sollten überprüft werden
</textarea>
</section>


<section data-markdown>
<textarea data-template>
### Beispiele links des Schwellwerts

Oben das Original, unten den Rekonstruktion und die gerundete Accuracy

<img src='img/autoencoder/broken.png'>

Tatsächlich sind alle gezeigten problematisch
</textarea>
</section>

<section data-markdown class="fragments">
<textarea data-template>
### Ergebnis

* Tatsächlich sind die meisten Test-Screenshots fehlerhaft
* Unser Schwellwert ist vernünftig, da wir nur wenige korrekte Screenshots haben
* Wir haben nicht die typischen verwischten Reproduktionen 
  * https://twitter.com/francoisfleuret/status/1382708204468060171
  * https://fleuret.org/dlc/#lecture-7
  * vermutlich weil wir kein MSE, sondern Log Loss nehmen
* sollte in weiteren Schritten auch für hauptsächlich korrekte Schreenshots ausprobiert werden     
</textarea>
</section>


<section data-markdown>
<textarea data-template>
### Referenz: Kapitel 8 von Machine Learning kurz & gut, 2. Auflage

<a href='https://oreilly.de/produkt/machine-learning-kurz-gut-2/'>
<img src='img/ml-buch-v2.jpg'>
</a>

<small>

https://colab.research.google.com/github/djcordhose/buch-machine-learning-notebooks/blob/master/kap8.ipynb
<br>
https://colab.research.google.com/github/DJCordhose/ml-workshop/blob/master/notebooks/intro/2021/intro_autoencoder.ipynb?hl=en
<br>
https://www.embarc.de/ml-buch-v2/

</small>
</textarea>
</section>

<section data-markdown>
### Programm

1. Visuelle Regressionstests
1. Autoencoder
1. Visuelle Regressionstests mit Autoencodern
1. _Ist das schon das Ende und was kann man damit noch machen?_
</section>

<section data-markdown>
## Die Ergebnisse sind immer noch nicht auf menschlichem Niveau

* Wir erkennen z.B. lange Zahlen und wissen, ob die sinnvoll sein können
* Überläufe sehen wir mit System 1, ohne nachzudenken
* Fehlende Knöpfe können auch menschen nur erschließen
</section>


<section data-markdown>
## Wie wird das Testen im Jahr 2030 aussehen?
    
https://www.menti.com/j6qqy5qr1p
</section>
    
<!-- <section data-markdown class="todo">
- The year is 2030. You're a software engineer at a company, writing tests for your program
	- [ ] https://twitter.com/TaliaRinger/status/1365433319572185092
	- [ ] I love this vision aside from the human writing the code and tests part.
	- [ ] I hope that by 2030 software synthesis could be possible mostly informal language input, in which human will only need to inspect the code and specification occasionally, but would not need to produce any.
	- [ ] (https://twitter.com/ChrSzegedy/status/1365780380733726720?s=03)
</section> -->

<section data-markdown>
    <textarea data-template>
### Testing von Frontends

<a href='https://www.heise.de/hintergrund/Zwischen-Erwartung-und-Ergebnis-End-to-End-Tests-fuer-Web-Frontends-5990683.html'>
<img src='img/autoencoder/heise-testing.png'>
</a>

https://www.heise.de/hintergrund/Zwischen-Erwartung-und-Ergebnis-End-to-End-Tests-fuer-Web-Frontends-5990683.html

</textarea>
</section>



<!-- <section data-markdown class="todo">
### Embedding vs Taxonomie
    
</section>
    
<section data-markdown>
    <textarea data-template>
### Taxonomien erscheinen natürlich


<img src='img/taxonomie-supermarkt.jpg'>

Alles ist in Hierarchien organisiert

</textarea>
</section>

<section data-markdown>
    <textarea data-template>
### Ein Ding ist an genau einem Ort

* Geht physisch mit Lokation auch nicht anders. 
* Und ein Produkt ist unauffindbar wenn es nicht an seinem erwarteten Platz ist

</textarea>
</section>


<section data-markdown class="todo">
    <textarea data-template>
### Embeddings sind viel flexibler

</textarea>
</section> -->


<section data-markdown>
    <textarea data-template>
### Mehr Links

* Mehr Beispiele für Autoencoder: https://colab.research.google.com/github/DJCordhose/ml-workshop/blob/master/notebooks/tf-intro/2020-01-autoencoder.ipynb
* Breite Auswahl an Beispielen aus dem Bereich Autoencoder, unsere Architektur ist davon abgeleitet: https://colab.research.google.com/github/ageron/handson-ml2/blob/master/17_autoencoders_and_gans.ipynb 

* Academische Betrachtungen
  * https://fleuret.org/dlc/#lecture-7
    * https://twitter.com/francoisfleuret/status/1382708204468060171
  * https://www.deeplearningbook.org/contents/autoencoders.html
  * Deconvolution erklärt: https://arxiv.org/pdf/1603.07285v1.pdf, S. 18ff
</textarea>
</section>


<section data-markdown>
    <textarea data-template>
# Vielen Dank

Visuelle Regressionstests mit Autoencodern

M3 2021 online, https://www.m3-konferenz.de/lecture.php?id=12674

Bleibt gern im Kontakt

Oliver Zeigermann (<a href='https://twitter.com/djcordhose'>@DJCordhose</a>)

Slides: https://bit.ly/m3-autoencoder

    </textarea>
</section>



</div>

<script src="reveal.js/js/reveal.js"></script>
<script src="lib/jquery-2.2.4.js"></script>

<script>
        // $('section:not([data-background])').attr('data-background', "background/white.jpg");
        // $('section:not([data-background])').attr('data-background', "background/pale-clouds.jpg");
        // $('section:not([data-background])').attr('data-background', "background/street.jpg");
        // $('section:not([data-background])').attr('data-background', "background/white-transparent.jpg");
</script>

<script>
        const isLocal = window.location.hostname.indexOf('localhost') !== -1 || 
                    window.location.hostname.indexOf('127.0.0.1') !== -1;

        $('.hide').remove();

        if (isLocal && !printMode) {
        } else {
            // only applies to public version
                $('.todo').remove();
                $('.preparation').remove();
                $('.local').remove();
        }
    
        Reveal.addEventListener( 'ready', function( event ) {
            // applies to all versions
            $('code').addClass('line-numbers');
    
            $('.fragments li').addClass('fragment')
    
            // make all links open in new tab
            $('a').attr('target', '_blank')
    
            if (isLocal && !printMode) {
                // only applies to presentation version
                Reveal.configure({ controls: false });
            } else {
                // only applies to public version
                // $('.fragment').removeClass('fragment');
            }

            // we do not like fragments
            // $('.fragment').removeClass('fragment');

        } );

</script>
    
<script>

    // Full list of configuration options available at:
    // https://github.com/hakimel/reveal.js#configuration
    Reveal.initialize({
        controls: true,
        progress: true,
        history: true,
        center: true,
        width: 1100,
        slideNumber: true,

        transition: 'fade', // none/fade/slide/convex/concave/zoom

        math: {
             mathjax: 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js',
            config: 'TeX-AMS_HTML-full'  // See http://docs.mathjax.org/en/latest/config-files.html
        },

        // Optional reveal.js plugins
        dependencies: [
            {
                src: 'reveal.js/lib/js/classList.js', condition: function () {
                return !document.body.classList;
            }
            },
            {
                src: 'reveal.js/plugin/markdown/marked.js', condition: function () {
                return !!document.querySelector('[data-markdown]');
            }
            },
            {
                src: 'reveal.js/plugin/markdown/markdown.js', condition: function () {
                return !!document.querySelector('[data-markdown]');
            }
            },
            {
                src: 'reveal.js/plugin/highlight/highlight.js', async: true, condition: function () {
                return !!document.querySelector('pre code');
            }, callback: function () {
                hljs.initHighlightingOnLoad();
            }
            },
            {src: 'reveal.js/plugin/zoom-js/zoom.js', async: true},
            {src: 'reveal.js/plugin/notes/notes.js', async: true},
            // https://github.com/mikemiles86/reveal-line-numbers
            {src: 'lib/js/line-numbers.js'},
            { src: 'reveal.js/plugin/math/math.js', async: true }

        ]
    });

</script>

</body>
</html>
