<!doctype html>
<html>

<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">

    <title>MCubed RNN</title>

    <link rel="stylesheet" href="reveal.js/css/reset.css">
    <link rel="stylesheet" href="reveal.js/css/reveal.css">
    <!-- <link rel="stylesheet" href="reveal.js/css/theme/black.css"> -->
    <link rel="stylesheet" href="reveal.js/css/theme/solarized.css">

    <!-- Theme used for syntax highlighting of code -->
    <link rel="stylesheet" href="reveal.js/lib/css/monokai.css">

    <style>
        /*pre code {*/
        /*display: block;*/
        /*padding: 0.5em;*/
        /*background: #FFFFFF !important;*/
        /*color: #000000 !important;*/
        /*}*/

        .right-img {
            margin-left: 10px !important;
            float: right;
            height: 500px;
        }

        .todo:before {
            content: 'TODO: ';
        }

        .todo {
            color: red !important;
        }

        code span.line-number {
            color: lightcoral;
        }

        .reveal pre code {
            max-height: 1000px !important;
        }

        img {
            border: 0 !important;
            box-shadow: 0 0 0 0 !important;
        }

        .reveal {
            -ms-touch-action: auto !important;
            touch-action: auto !important;
        }

        .reveal h2,
        .reveal h3,
        .reveal h4 {
            letter-spacing: 2px;
            font-family: 'Amiri', serif;
            /* font-family: 'Times New Roman', Times, serif; */
            font-weight: bold;
            font-style: italic;
            letter-spacing: -2px;
            text-transform: none !important;
        }

        .reveal em {
            font-weight: bold;
        }

        .reveal .step-subtitle h1 {
            letter-spacing: 1px;
        }

        .reveal .step-subtitle h2,
        .reveal .step-subtitle h3 {
            text-transform: none;
            font-style: italic;
            font-weight: normal;
            /* font-weight: 400; */
            /* font-family: 'Amiri', serif; */
            font-family: 'Lobster', serif;
            letter-spacing: 1px;
            color: #2aa198;
            text-decoration: underline;
        }

        .reveal .front-page h1,
        .reveal .front-page h2 {
            font-family: "League Gothic";
            font-style: normal;
            text-transform: uppercase !important;
            letter-spacing: 1px;
        }

        .reveal .front-page h1 {
            font-size: 2.5em !important;
        }

        .reveal .highlight {
            background-color: #D3337B;
            color: white;
        }

        .reveal section img {
            background: none;
        }

        .reveal img.with-border {
            border: 1px solid #586e75 !important;
            box-shadow: 3px 3px 1px rgba(0, 0, 0, 0.15) !important;
        }

        .reveal li {
            margin-bottom: 8px;
        }

        /* For li's that use FontAwesome icons as bullet-point */
        .reveal ul.fa-ul li {
            list-style-type: none;
        }
    </style>


    <!-- Printing and PDF exports -->
    <script>
        var link = document.createElement('link');
        link.rel = 'stylesheet';
        link.type = 'text/css';
        var printMode = window.location.search.match(/print-pdf/gi);
        link.href = printMode ? 'reveal.js/css/print/pdf.css' : 'reveal.js/css/print/paper.css';
        document.getElementsByTagName('head')[0].appendChild(link);
    </script>
</head>

<body>
    <div class="reveal">
        <div class="slides">

            <section data-markdown class="preparation">
                <textarea data-template>
### Preparation
* open Local Server as a fallback: http://localhost:8888/notebooks/time-series-rnn-full-predict.ipynb
                </textarea>
            </section>


<!-- 
Processes in the world around us are not static, but evolve over time. Because of this time series data 
is the most common kind of data when we look at real world processes. Recurrent neural networks are one of 
the most successful tools for time series forecasts as they are able to take the 
past into account.

Based on the example of Germany's energy consumption I will lead you though the process of analysing, and preparing the data, 
and then train a model on it and see how well it performs. We will also investigate which parameters have an effect on the performance
of the model.   

I will share the complete code as a Colab notebook so you can start with your time series project right after the talk.
 -->
        <section>
        <h2>Introduction to Time Series Prediction using Recurrent Neural Networks</h2>
        <p><a target="_blank" href="https://www.mcubed.london/sessions/introduction-to-time-series-prediction-using-recurrent-neural-networks/">
            MCubed, London, October 2019
        </a></p>
        <h4><a href="http://zeigermann.eu">Oliver Zeigermann</a> / <a href="http://twitter.com/djcordhose">@DJCordhose</a>
        </h4>
        <p><small><a href="http://bit.ly/rnn-mcubed">
            http://bit.ly/rnn-mcubed
        </a></small></p>
    </section>

    <section data-markdown>
        <textarea data-template>
### Germany's Consumption of Energy over time

<img src='img/consumption-overview.png' height="450">

_Could we do a reasonable forecast?_
</textarea>
</section>


<section data-markdown>
        <textarea data-template>
### Going through our example in a Colab Notebook

https://colab.research.google.com/github/DJCordhose/ml-workshop/blob/master/notebooks/tf2/time-series-rnn-full-predict.ipynb

</textarea>
</section>


<section data-markdown>
        <textarea data-template>
#### Before you get tempted, read this

<img src='img/fchollet-stock-prices.png'>
<small>

https://twitter.com/fchollet/status/1177633367472259072
</small>
            </textarea>
</section>

<section data-markdown class="fragments">
        <textarea data-template>
## Open Question
_How would you map_
* any number of input time steps
* with any number of features
* to any number of output time steps
* with any number of features
            </textarea>
</section>
    
<section data-markdown class="fragments">
    <textarea data-template>
### Surprising Solution: RNN Encoder-Decoder

* RNN Encoder-Decoder consists of two recurrent neural networks (RNN)
* they act as an encoder and a decoder pair
* encoder maps a variable-length source sequence to _a fixed-length vector_, the _latent representation_
* all the temporal information as lost in the latent representation
* decoder maps the vector representation back to a variable-length target sequence

<small>

https://arxiv.org/abs/1406.1078
<br>
https://machinelearningmastery.com/encoder-decoder-long-short-term-memory-networks/

</small>
    </textarea>
</section>

<section data-markdown>
        <textarea data-template>
### Example Application: Sequence to Sequence translations

* could be interpreted as sequential embedding
* fixed-length vector between decoder and encoder is the latent space

<img src='img/seq/encdec.jpg'>

<small>

https://github.com/tensorflow/nmt
</small>
</textarea>
</section>

<section data-markdown>
    <textarea data-template>
#### You can even describe all networks as a combination of encoder / decoder

<img src='img/embeddings/encoder-decoder-everywhere.png' height="530">

<small style="font-size: large">

https://medium.com/tensorflow/mit-deep-learning-basics-introduction-and-overview-with-tensorflow-355bcd26baf0
</small>
    </textarea>
</section>


<section data-markdown>
        <textarea data-template>
### Encoder / Decoder Architectures

_This is mostly about the sequence of layers_ 
<pre><code contenteditable data-trim class="fragment line-numbers python">
# Encoder (nothing new)    

model.add(Input(shape=(n_steps_in, n_features)))
model.add(LSTM(units=ENCODER_SIZE, activation='relu'))
                </code></pre>

<pre><code contenteditable data-trim class="fragment line-numbers python">
# Latent Space (nothing new)    

model.add(Dense(units=ENCODING_DIM, activation='relu'))
model.add(Dense(units=ENCODING_DIM, activation='relu'))
                </code></pre>

<pre><code contenteditable data-trim class="fragment line-numbers python">
# Decoder    

# rolls out the latent space for each of the desired output steps
model.add(RepeatVector(n_steps_out))
model.add(LSTM(units=DECODER_SIZE, activation='relu', return_sequences=True))
model.add(Dense(units=1)) # just to combine
                </code></pre>

<small>

https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/keras/layers

</small>                
            </textarea>
</section>
    
<section data-markdown>
        <textarea data-template>
## Using an encoder/decoder architecture
### Time Series Forecasting

https://colab.research.google.com/github/DJCordhose/ml-workshop/blob/master/notebooks/tf2/time-series-encoder-decoder.ipynb
        
            </textarea>
</section>

<section data-markdown class="fragments">
    <textarea data-template>
### Wrap-Up

_Feel free to say "Hello" after the talk_

* results look pretty good
* no dramatic difference between training and test data
* peaks and valleys are underestimated very often
* encoder/decoder architectures allow to make any number of predictions from any number of past events 

_Introduction to Time Series Prediction using Recurrent Neural Networks, MCubed, London, October 2019_

<small>
<a href="http://zeigermann.eu">Oliver Zeigermann</a> / <a href="http://twitter.com/djcordhose">@DJCordhose</a>
<br>
Slides: http://bit.ly/rnn-mcubed
</small>

</textarea>
</section>


        </div>
    </div>

    <script src="reveal.js/js/reveal.js"></script>
    <script src="lib/jquery-2.2.4.js"></script>

    <script>
        $('section:not([data-background])').attr('data-background', "background/white.jpg");
    </script>
    <script>
        const isLocal = window.location.hostname.indexOf('localhost') !== -1 || 
                    window.location.hostname.indexOf('127.0.0.1') !== -1;
    
        if (isLocal && !printMode) {
        } else {
            // only applies to public version
                $('.todo').remove();
                $('.preparation').remove();
                $('.local').remove();
        }
    
        Reveal.addEventListener( 'ready', function( event ) {
            // applies to all versions
            $('code').addClass('line-numbers');
    
            $('.fragments li').addClass('fragment')
    
            // make all links open in new tab
            $('a').attr('target', '_blank')
    
            if (isLocal && !printMode) {
                // only applies to presentation version
                Reveal.configure({ controls: false });
            } else {
                // only applies to public version
                $('.fragment').removeClass('fragment');
            }
    
    
        } );
    </script>
    
    <script>
        // More info about config & dependencies:
        // - https://github.com/hakimel/reveal.js#configuration
        // - https://github.com/hakimel/reveal.js#dependencies
        Reveal.initialize({
            controls: true,
            progress: false,
            history: true,
            center: true,
            width: 1100,

            math: {
                mathjax: 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js',
                config: 'TeX-AMS_HTML-full'  // See http://docs.mathjax.org/en/latest/config-files.html
            },

            dependencies: [
                { src: 'reveal.js/plugin/markdown/marked.js' },
                { src: 'reveal.js/plugin/markdown/markdown.js' },
                { src: 'reveal.js/plugin/notes/notes.js', async: true },
                { src: 'reveal.js/plugin/highlight/highlight.js', async: true },
                { src: 'lib/js/line-numbers.js' },
                { src: 'reveal.js/plugin/math/math.js', async: true }
            ]
        });
    </script>
</body>

</html>