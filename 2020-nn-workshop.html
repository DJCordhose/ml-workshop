<!doctype html>
<html>

<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">

    <title>Deep Learning TF2 Workshop</title>

    <link rel="stylesheet" href="reveal.js/css/reset.css">
    <link rel="stylesheet" href="reveal.js/css/reveal.css">
    <!-- <link rel="stylesheet" href="reveal.js/css/theme/black.css"> -->
    <link rel="stylesheet" href="reveal.js/css/theme/solarized.css">

    <!-- Theme used for syntax highlighting of code -->
    <link rel="stylesheet" href="reveal.js/lib/css/monokai.css">

    <style>
        /*pre code {*/
        /*display: block;*/
        /*padding: 0.5em;*/
        /*background: #FFFFFF !important;*/
        /*color: #000000 !important;*/
        /*}*/

        .right-img {
            margin-left: 10px !important;
            float: right;
            height: 500px;
        }

        .todo:before {
            content: 'TODO: ';
        }

        .todo {
            color: red !important;
        }

        code span.line-number {
            color: lightcoral;
        }

        .reveal pre code {
            max-height: 1000px !important;
        }

        img {
            border: 0 !important;
            box-shadow: 0 0 0 0 !important;
        }

        .reveal {
            -ms-touch-action: auto !important;
            touch-action: auto !important;
        }

        .reveal h2,
        .reveal h3,
        .reveal h4 {
            letter-spacing: 2px;
            font-family: 'Amiri', serif;
            /* font-family: 'Times New Roman', Times, serif; */
            font-weight: bold;
            font-style: italic;
            letter-spacing: -2px;
            text-transform: none !important;
        }

        .reveal em {
            font-weight: bold;
        }

        .reveal .step-subtitle h1 {
            letter-spacing: 1px;
        }

        .reveal .step-subtitle h2,
        .reveal .step-subtitle h3 {
            text-transform: none;
            font-style: italic;
            font-weight: normal;
            /* font-weight: 400; */
            /* font-family: 'Amiri', serif; */
            font-family: 'Lobster', serif;
            letter-spacing: 1px;
            color: #2aa198;
            text-decoration: underline;
        }

        .reveal .front-page h1,
        .reveal .front-page h2 {
            font-family: "League Gothic";
            font-style: normal;
            text-transform: uppercase !important;
            letter-spacing: 1px;
        }

        .reveal .front-page h1 {
            font-size: 2.5em !important;
        }

        .reveal .highlight {
            background-color: #D3337B;
            color: white;
        }

        .reveal section img {
            background: none;
        }

        .reveal img.with-border {
            border: 1px solid #586e75 !important;
            box-shadow: 3px 3px 1px rgba(0, 0, 0, 0.15) !important;
        }

        .reveal li {
            margin-bottom: 8px;
        }

        /* For li's that use FontAwesome icons as bullet-point */
        .reveal ul.fa-ul li {
            list-style-type: none;
        }
    </style>


    <!-- Printing and PDF exports -->
    <script>
        var link = document.createElement('link');
        link.rel = 'stylesheet';
        link.type = 'text/css';
        var printMode = window.location.search.match(/print-pdf/gi);
        link.href = printMode ? 'reveal.js/css/print/pdf.css' : 'reveal.js/css/print/paper.css';
        document.getElementsByTagName('head')[0].appendChild(link);
    </script>
</head>

<body>
    <div class="reveal">
        <div class="slides">

            <section data-markdown class="preparation">
                <textarea data-template>
### Preparation
* Output layer exercise as paper
* 2 kinds of post its for question and done
                </textarea>
            </section>

<section data-markdown class='local' style="font-size: xx-large">
        <textarea data-template>
### Workshop: Introduction to Deep Learning with TensorFlow 2

_Make sure you are prepared_
1. #wifi Name: xxx, pwd: xxx
1. Open this slide deck: XXX
1. Make sure you are ready to work with Colab
   * open https://colab.research.google.com/notebooks/welcome.ipynb in Chrome (IE will not work)
   * make it run using the "Run All" command from the "Runtime" menu
   * you need to allow execution and must either have a Google login or are willing to create one
   * Go through the notebook and make yourself comfortable with Colab

_Talk to your neighbors or ask Olli for help_   
    </textarea>
    </section>


 <section data-markdown class="todo hide">
        <textarea data-template>
 * Wifi erste Folie 
 * bit.ly link
 * Drive File
        </textarea>
    </section>

    <section data-markdown class="todo">
Notebooks für NN Kurs
- [ ] Ters Folien ausbeuten, insbesondere Cross Entropie:
    - [ ] https://github.com/parrt/fundamentals-of-deep-learning/tree/main/notebooks
    - [ ] https://github.com/parrt/fundamentals-of-deep-learning/raw/main/lectures/intro.pptx
- [ ] CNN
- [ ] RNN mit Energieversorgung
- [ ] Autoencoder, halber Tag
- [ ] Struktur anderer Kurs: https://github.com/data-psl/lectures2020
- [ ] Regression in 2. Notebook sehr einfach
</section>

    <section data-markdown class="todo">
        <textarea data-template>
* Neurungen aus SSH nehmen
  * Notebook 
  * Folien-Satz           
</textarea>
</section>

<section data-markdown class="todo">
    <textarea data-template>
### Tabular        
* Grundfrage: NN was ist in, was ist out?

* Reihenfolge anders: erst Tabular als Introduction, dann die detailierten Notebooks        
* Tabular auf neue Grafiken etc. umbauen wie in ML Intro
</textarea>
</section>

<section data-markdown class="todo">
        <textarea data-template>
### Auf neueste Notebooks umstellen
* https://colab.research.google.com/github/DJCordhose/ml-workshop/blob/master/notebooks/intro/nn-2021.ipynb?hl=en            
  * Braucht einen halben Tag minimum
* https://colab.research.google.com/github/DJCordhose/ml-workshop/blob/master/notebooks/intro/nn-03-regularization.ipynb?hl=en            
  * Kann kurz oder lang gehen
* https://colab.research.google.com/github/DJCordhose/ml-workshop/blob/master/notebooks/intro/nn-04-images.ipynb?hl=en            
  * Auf Ablauf von SSH anpassen
  * Noch grundlegendere Einführung in CNN, mehr Übungen
</textarea>
</section>


<section data-markdown class="todo">
    Ryan Holbrook (@ryanpholbrook) twitterte um 2:41 PM on Mi., Dez. 30, 2020:
New blog post: Visualizing the Loss Landscape of a Neural Network

Code implementation of ideas from: https://t.co/MvofadkdIa https://t.co/QQt2qsqXuB
(https://twitter.com/ryanpholbrook/status/1344277352218570755?s=03)
</section>


<section data-markdown class="todo">
    <textarea data-template>
### Abschluss-Übungen nach 01, 02 und 03

- Male deinen eigenen Datensatz und versuche ihn zu fitten
- Entweder Line Chart für 01 oder Scatter Plot für 02
- Generalisierung sicher stellen (wie in 03 gelernt)
- Code vorgeben, der das Laden kann

https://drawdata.xyz/
</textarea>
</section>

<section data-markdown class="todo">
    <textarea data-template>
Story für Image CNN

Wie hat man vor ML Strukturen in Bildern erkannt?
- Filter-Kernel
- Idee: diese nehmen, um auch Strukturen in Bildern zu isolieren
- Parameter sind trainierbar
- Erste Schichten machen Feature Extraktion 
</textarea>
</section>

<section data-markdown class="todo">
    <textarea data-template>
Sparsity aus den folgenden Folien für CNN einbauen
</textarea>
</section>

<section data-markdown>
    <textarea data-template>
<img src='img/sparsity-occam.png'>

<small>
Sparsity and Parsimonious Models: <a href='https://youtu.be/9eGMJ3-wmm0'>https://youtu.be/9eGMJ3-wmm0</a>
</small>
    </textarea>
</section>

<section data-markdown>
    <textarea data-template>
<img src='img/sparsity-newton.jpg'>

<small>
Sparsity and Parsimonious Models: <a href='https://youtu.be/9eGMJ3-wmm0'>https://youtu.be/9eGMJ3-wmm0</a>
</small>
    </textarea>
</section>

<section data-markdown>
    <textarea data-template>
<img src='img/sparsity-ptolemy.png'>

<small>
Sparsity and Parsimonious Models: <a href='https://youtu.be/9eGMJ3-wmm0'>https://youtu.be/9eGMJ3-wmm0</a>
</small>
    </textarea>
</section>

<section data-markdown>
    <textarea data-template>
### Why Sparse Models?
* Contribute to Regularization
* Generally more interpretable (not really true for CNNs)
* Reduce Memory and Compute Requirements
  * might even make the difference between "can predict on CPU" and "needs GPUs scalably"        
    </textarea>
</section>

    <section data-markdown class="todo">
        <textarea data-template>
### Custom Loss Function

https://twitter.com/fchollet/status/1296292123768025090?s=09
</textarea>
</section>

<section data-markdown class="todo">
    <textarea data-template>
### Hardware Lotterie: warum erst jetzt DL

https://arxiv.org/abs/2009.06489?s=09
</textarea>
</section>


    <section data-markdown class="todo">
        <textarea data-template>
### TF 2.3    

https://blog.tensorflow.org/2020/07/whats-new-in-tensorflow-2-3.html

* https://twitter.com/TensorFlow/status/1287832408947978240?s=09

*    Ludwig Stumpp (@ludwig_stumpp) tweeted at 3:11 pm on Sun, Jul 26, 2020:
Starting with #Tensorflow 2.3, this is all it needs to train a simple and fast classificator with 90% validation accuracy using #transferLearning.

Model includes preprocessing steps thanks to the latest #keras features in the preprocessing module. https://t.co/PLdt7FJHiu
(https://twitter.com/ludwig_stumpp/status/1287374973397602305?s=09)
</textarea>
</section>

<section data-markdown class="todo">
    <textarea data-template>
## Training für GANs
https://keras.io/guides/customizing_what_happens_in_fit/
</textarea>
</section>

<section data-markdown class="todo">
    <textarea data-template>
## Best Practices

Alles Hidden ReLU außer es trainiert dann nicht

3 Layers
500 Neuronen
VGG Untermenge mit Dropout
GRU
für letzten Layer passt zur Predition  und Loss wiederum dazu

</textarea>
</section>

<section data-markdown class="todo">
    <textarea data-template>
## Losses

* regression: linear (or any other activation if the range of values is limited) and MSE 
* multi class: softmax with cross entropy
* multi-label output would be sigmoid on final layer with binary cross entropy, each output node would encode an hypothesis of its own

https://stats.stackexchange.com/questions/260505/should-i-use-a-categorical-cross-entropy-or-binary-cross-entropy-loss-for-binary

1. Binary classification: two exclusive classes
2. Multi-class classification: more than two exclusive classes
3. Multi-label classification: just non-exclusive classes
Here, we can say

1. In the case of (1), you need to use binary cross entropy.
2. In the case of (2), you need to use categorical cross entropy.
3. In the case of (3), you need to use binary cross entropy.

https://gombru.github.io/2018/05/23/cross_entropy_loss/
https://towardsdatascience.com/cross-entropy-for-classification-d98e7f974451
https://machinelearningmastery.com/how-to-choose-loss-functions-when-training-deep-learning-neural-networks/
https://towardsdatascience.com/understanding-binary-cross-entropy-log-loss-a-visual-explanation-a3ac6025181a
https://www.youtube.com/watch?v=ErfnhcEV1O8

Allgemeine Beschreinung Cross-Entropie: https://github.com/parrt/fundamentals-of-deep-learning/blob/main/lectures/intro.pptx

Bisschen Spielcode mit Losses: https://colab.research.google.com/drive/1v5zHdY7ezAV22Svthz75WhNlrZOkZaDm?hl=en#scrollTo=cyAbtZKaAtzg
</textarea>
</section>


<section data-markdown class="todo">
    <textarea data-template>
## Basics/Intro von Goofs Slides klauen

https://github.com/parrt/fundamentals-of-deep-learning/blob/main/lectures/intro.pptx

</textarea>
</section>

<section data-markdown class="todo">
    <textarea data-template>

François Chollet (@fchollet) twitterte um 11:16 PM on So., Nov. 29, 2020:
Deep learning isn't a science, but rather an ever-changing set of empirically-derived engineering best practices, woven together by over-claiming, unreliable narratives.
(https://twitter.com/fchollet/status/1333173017678028802?s=03)
</textarea>
</section>
    

<section data-markdown class="todo">
    <textarea data-template>
### Auflockerung für Logistic Regression Notebook

https://twitter.com/ChristophMolnar/status/1338756572349140996?s=20
</textarea>
</section>

            <section>
            <br>
            <br>
            <h2>Introduction to Deep Learning with TensorFlow 2</h2>
            <!-- <h3>1-2 day workshop</h3> -->
            <br>
            <br>
            <h4><a href="http://zeigermann.eu">Oliver Zeigermann</a> / 
                <a href="http://twitter.com/djcordhose">@DJCordhose</a>
            </h4>
            <p><small><a href="https://djcordhose.github.io/ml-workshop/2020-nn-workshop.html">
                https://djcordhose.github.io/ml-workshop/2020-nn-workshop.html
            </a></small></p>
        </section>


<section data-markdown class="hide">
    <textarea data-template>
## Up to 4 parts, half a day each

1. Basics
1. Tabular input
1. Image input
1. Sequences and time series
</textarea>
</section>


<section data-markdown>
    <textarea data-template>
# Basics
</textarea>
</section>



<section data-markdown class="local hide">
    <textarea data-template>
## Questions, comments, critique are welcome at any time
</textarea>
</section>

<section data-markdown  class="hide" style="font-size: x-large">
    <textarea data-template>        
## Post Its

<img src='img/post-its.jpg' height="400">

* Stick the red one to your laptop to indicate you need help (please remove after you have been helped)
* Do the same with the blue one to indicate you are done with an exercise (please remove at the beginning of each exercise)
</textarea>
</section>

<section data-markdown class="hide">
    <textarea data-template>        
## Scatchpad to share links and information

On Google Drive, everyone with link can read and edit

<!-- http://bit.ly/mcubed-nn-scratch -->
<!-- https://docs.google.com/document/d/17jNrh-eeeCSHGIMry7xNobc8UCkqVkzUf7o2pT7e4g0/edit?usp=sharing -->
</textarea>
</section>

<section data-markdown class="local hide">
        <textarea data-template>
## Introduce yourself to your neighbors, please

* What are you working on?
* What do you want to achieve with TensorFlow?
* What do you already know about ML and TensorFlow?
* If necessary please help your neighbors to get to theses slides 
    and make the first notebook run (described in first slide)

        </textarea>
    </section>

<section data-markdown class="local hide fragments" style="font-size: x-large">
    <textarea data-template>
### What is your background?

Technical
* Data Science
* Programming
* Classic Machine Learning
* Neural Networks
* What else?

Tools
* Matlab
* R
* Python
* Scikit-learn
* TensorFlow 1/2
* Pytorch
* What else?
</textarea>
</section><section>
    <img src='img/data.png'>
</section>

<section data-markdown>
        <textarea data-template>
## Networks for Tabular and Structured data

<a href='2020-tabular.html'>Fully Connected Layers</a>

</textarea>
</section>


<section data-markdown style="font-size: xx-large;">
        <textarea data-template>
### Interactive, online introduction to Neural Networks with TensorFlow

1. Regression: https://colab.research.google.com/github/DJCordhose/ml-workshop/blob/master/notebooks/tf-intro/2020-02-basics-regression.ipynb
1. Classification: https://colab.research.google.com/github/DJCordhose/ml-workshop/blob/master/notebooks/tf-intro/2020-01-basics-classification.ipynb
1. Regularization (optional, also covered in more conceptual detail in tabular data): https://colab.research.google.com/github/DJCordhose/ml-workshop/blob/master/notebooks/tf-intro/2020-01-basics-regularization.ipynb
</textarea>
</section>


<section data-markdown>
    <textarea data-template>
### Progressive disclosure of complexity in the Keras API

<img src='img/fchollet-keras-progressive-disclosure.png'>

<small>

https://twitter.com/fchollet/status/1231285340335267840 

</small>
</textarea>
</section>


<section data-markdown>
    <textarea data-template>
### Building    

<img src='img/keras-abstractions-builidng.jpg'>
</textarea>
</section>

<section data-markdown>
    <textarea data-template>
### Training

<img src='img/keras-abstractions-training.jpg'>

</textarea>
</section>

<section>
    <img src='img/data.png'>
</section>

<section data-markdown>
    <textarea data-template>
### Understanding CNNs  

_Network to process images_

<a href='https://poloclub.github.io/cnn-explainer/'>
<img src='img/cnn-explainer.png' height="400">
</a>
<small>

https://poloclub.github.io/cnn-explainer/
</small>
</textarea>
</section>


<section data-markdown>
        <textarea data-template>
## Networks for Images

https://colab.research.google.com/github/DJCordhose/ml-workshop/blob/master/notebooks/tf-intro/2020-01-images.ipynb

</textarea>
</section>

<section>
    <img src='img/data.png'>
</section>

<section data-markdown>
        <textarea data-template>
## Networks for Sequences, Time Series and Texts

<a href='2020-rnn.html'>Recurrent Neural Networks: RNNs</a>

</textarea>
</section>

<section data-markdown>
    <textarea data-template>
# General Concepts

</textarea>
</section>

<section data-markdown class="hide">
    <textarea data-template>
### Time for some bad news

<img src='img/weird-val-accuracy.png'>

</textarea>
</section>

<section data-markdown style="font-size: xx-large" class="hide">
    <textarea data-template>
### The real world looks different

_All the shown examples are highly idealised_
* Training often behaves much less graceful in the real world
* it does not train linearly
* sudden jumps in loss can occur any time
* can take forever to train
* might ruin your night sleep and family live (let me just quickly check on the training progress) 
* Real world data might not match training data
* You might not even know the real data
* Struggle to find/get good quality data in the first place 
        </textarea>
    </section>

<section data-markdown>
    <textarea data-template>
### Generalization

<img src='img/data-and-the-world.jpg' height="500px">

<small>

https://twitter.com/DJCordhose/status/1256950659653480448
</small>
    </textarea>
</section>

<section data-markdown>
    <textarea data-template>
#### Even seemingly simple tasks are so far unsolved

recognizing digits and numbers in natural scene images

<img src='img/house_numbers.png' height="450px">

<small>

http://ufldl.stanford.edu/housenumbers/
</small>
    </textarea>
</section>


<section data-markdown>
    <textarea data-template>
### ML Models are restricted by their training data

<img src='img/ml-view-on-data.png' height="350px">

<small>

https://twitter.com/jacobmenick/status/1260658763687538688
</small>
    </textarea>
</section>


<section data-markdown>
    <textarea data-template>
### Models will only learn what you feed them

<img src='img/facebook-chatbot.png' height="350px">

<small>

https://twitter.com/TomerUllman/status/1259834838829465601
https://twitter.com/mikiobraun/status/1260115051417124869
</small>
    </textarea>
</section>


<section data-markdown>
    <textarea data-template>
## Concepts: Metrics        

* Loss functions need to be differentiable
* This often restricts how speaking they are in terms of business value
* Metrics do not have that restriction, but take the same parameters

    </textarea>
</section>

<section data-markdown>
    <textarea data-template>
### Regression Metric: R<sup>2</sup>

_loosely speaking: how much better is this than predicting the constant mean_

* 0 would mean just as good
* 1 is perfect
* neg. would mean even worse
* it can become arbitrarily worse

<small>

https://en.wikipedia.org/wiki/Coefficient_of_determination
</small>
    </textarea>
</section>

<section data-markdown>
    <textarea data-template>
### Understanding R<sup>2</sup>

<img src='img/r2.png' height="450">

<small>

CC BY-SA 3.0, https://commons.wikimedia.org/wiki/File:Coefficient_of_Determination.svg
</small>
    </textarea>
</section>


<section data-markdown>
    <textarea data-template>
### Basic Classification Metric

<script type="math/tex; mode=display">
accuracy = {\frac {correct\;predictions}{number\;of\;samples}}
</script>

_often given for training and test data separately_
</textarea>
</section>


<section data-markdown>
    <textarea data-template>
### Demo: Anomagram 
<a href='https://victordibia.github.io/anomagram/#/'>
<img src='img/embeddings/anomagram-inference.gif' height="450">
</a>
<br>
<small>

https://github.com/victordibia/anomagram        
https://victordibia.github.io/anomagram/#/
    
</small>
</textarea>
</section>

<section data-markdown class="fragment">
    <textarea data-template>
### What would you rather have?

1. Attest a heart anomaly to someone who has none (aka Precision)
1. Miss an actual anomaly (aka Recall, hit-rate)

    </textarea>
</section>


<section data-markdown style="font-size: xx-large">
    <textarea data-template>
### Reference: Metrics

* _Precision_: percentage of positive predictions that are correct
    * true positive / true positive + _false positive (predicted as true, but is false)_
* _Recall_ (aka hit rate): proportion of actual positives that were correctly predicted
    * true positive / true positive + _false negative (predicted as false, but is true)_
* low enough threshold will yield excellent recall but reduced precision
* F1 score is the harmonic mean of the precision and recall

<small>

https://zackakil.github.io/precision-recall-playground/
<br>
https://towardsdatascience.com/understanding-confusion-matrix-a9ad42dcfd62
<br>
https://towardsdatascience.com/understanding-auc-roc-curve-68b2303cc9c5
</small>
</textarea>
</section>


<section data-markdown>
    <textarea data-template>
### Experiment with Metrics  

<a href='https://zackakil.github.io/precision-recall-playground/'>
<img src='img/metrics.png' height="400">
</a>
<small>

https://zackakil.github.io/precision-recall-playground/
</small>
</textarea>
</section>

<section data-markdown>
    <textarea data-template>
### What is Deep Learning?

_Yann LeCun:_
* DL is constructing networks of parameterized functional modules & training them from examples using gradient-based optimization
* A multi-layer neural net trained with backprop is, of course, a special instance of DL. 
Although, a NN with only one hidden layer is a little too simple to deserve the  adjective "deep".

<small>

https://twitter.com/ylecun/status/1209497021398343680
https://twitter.com/ylecun/status/1209621242652844032
https://www.facebook.com/722677142/posts/10156463919392143/
https://www.facebook.com/yann.lecun/posts/10155003011462143    

</small>
</textarea>
</section>

<section data-markdown>
    <textarea data-template>
### What is Deep Learning?

_François Chollet:_
* DL is the idea of doing representation learning via a chain of learned feature extractors
* It's all about describing some input data via *deep hierarchies of features*, where features are *learned*
* It does not need to use gradient-based optimization

<small>

https://twitter.com/fchollet/status/1210031900695449600
https://twitter.com/fchollet/status/1210126376101130241

</small>
</textarea>
</section>


<section data-markdown style="font-size: xx-large">
    <textarea data-template>
## Practical advice from a master of his craft

_Challenges of training neural nets_
1. Neural net training is a leaky abstraction - you need to understand what is going on
1. Neural net training fails silently - the possible error surface is large

_The recipe_
1. Understand your data
1. Make one simple experiment after the other
1. Make your model good / large enough to overfit on a batch
1. Regularize on full data set
1. Tune and scrape the barrel

<small>

https://karpathy.github.io/2019/04/25/recipe/    

</small>
</textarea>
</section>

<section data-markdown>
    <textarea data-template>
## Challenges of Deep Learning

* deep learning is more an art than a science
* we can provide guidelines as to what is likely to work or not
* ultimately every problem is unique 
* you will have to try and evaluate different strategies empirically
* currently there is no theory that will tell you in advance precisely what you should do to optimally solve a problem
* You must try and iterate

<small>

François Chollet in [Deep Learning with Python (Manning Publications)](https://www.manning.com/books/deep-learning-with-python?a_aid=keras&a_bid=76564dff)    

</small>

</textarea>
</section>


<section data-markdown>
        <textarea data-template>
# Finally
    
</textarea>
</section>

<section data-markdown>
        <textarea data-template>
### Bringing TensorFlow to the Edge

* https://www.tensorflow.org/lite
  * Works for Android: https://www.tensorflow.org/lite/guide/android
  * And iOS: https://www.tensorflow.org/lite/guide/ios
  * How to deploy Keras models on Android via TFLite: https://medium.com/@margaretmz/e2e-tfkeras-tflite-android-273acde6588
* https://www.tensorflow.org/js/
  * Works on any modern browser using the GPU via WebGL
</textarea>
</section>

<section data-markdown>
    <textarea data-template>

<img src='img/nn-overview.png' height="500">        
<small>
https://towardsdatascience.com/the-mostly-complete-chart-of-neural-networks-explained-3fb6f2367464    
</small>
</textarea>
</section>

<section data-markdown style="font-size: large">
    <textarea data-template>

## Overview of Notebooks

_Basics_
* https://colab.research.google.com/github/DJCordhose/ml-workshop/blob/master/notebooks/tf-intro/2020-02-basics-regression.ipynb
* https://colab.research.google.com/github/DJCordhose/ml-workshop/blob/master/notebooks/tf-intro/2020-01-basics-classification.ipynb
* https://colab.research.google.com/github/DJCordhose/ml-workshop/blob/master/notebooks/tf-intro/2020-01-basics-regularization.ipynb

_Tabular Data / Dense Networks_
* https://colab.research.google.com/github/djcordhose/ml-workshop/blob/master/notebooks/tf2/tf-dense-insurance-model.ipynb
* https://colab.research.google.com/github/djcordhose/ml-workshop/blob/master/notebooks/tf2/tf-dense-insurance-training.ipynb
* https://colab.research.google.com/github/djcordhose/ml-workshop/blob/master/notebooks/tf2/tf-dense-insurance-reg.ipynb
* https://colab.research.google.com/github/djcordhose/ml-workshop/blob/master/notebooks/tf2/tf-dense-insurance-final.ipynb
* https://colab.research.google.com/github/djcordhose/ml-workshop/blob/master/notebooks/classic/strategies.ipynb

_Sequential Data / RNN_
* https://colab.research.google.com/github/DJCordhose/ml-workshop/blob/master/notebooks/tf-intro/2020-01-rnn-basics.ipynb
* https://colab.research.google.com/github/DJCordhose/ml-workshop/blob/master/notebooks/tf-intro/2020-01-rnn-advanced.ipynb
* https://colab.research.google.com/github/DJCordhose/ml-workshop/blob/master/notebooks/tf-intro/2020-01-time-series.ipynb
* https://colab.research.google.com/github/DJCordhose/ml-workshop/blob/master/notebooks/tf2/time-series-encoder-decoder.ipynb

_Image Data / Convolutional Networks_
* https://colab.research.google.com/github/DJCordhose/ml-workshop/blob/master/notebooks/tf-intro/2020-01-images.ipynb
* https://colab.research.google.com/github/DJCordhose/ml-workshop/blob/master/notebooks/tf2/images-intro.ipynb

</textarea>
</section>

<section data-markdown style="font-size: xx-large;">
    <textarea data-template>
## Teaching Resources by Keras author François Chollet

* https://keras.io/getting_started/
* A list of up-to-date Keras examples in one place: https://keras.io/examples/
* A list of in-depth guides to learn modern Keras: https://keras.io/guides/

<!-- * Intro to Keras for Researchers: https://colab.research.google.com/drive/169PfzM0kvtA5UP4k6Sl1yCG9tsE2MLia
* Intro to Keras for Engineers: https://colab.research.google.com/drive/1lWUGZarlbORaHYUZlF9muCgpPl8pEvve
* Image classification from scratch: https://colab.research.google.com/drive/1umJnCp8tZ7UDTYSQsuWdKRhqbHts38AC
* Deep Dream:  https://colab.research.google.com/drive/18XPdEDVYdr_ODAvW0DrWRCRC25tvTuCE
* Activation Maps:  https://colab.research.google.com/drive/1CJQSVaXG1ceBQGFrTHnt-pt1xjO4KFDe
* Transfer Learning:  https://colab.research.google.com/drive/17vHSAj7no7RMdJ18MJomTf8twqw1suYC
* VAE:  https://colab.research.google.com/drive/1COeSoasrpY-w3uF1JPVksLEjx4Tx2ns5 -->

                            </textarea>
    </section>

<section data-markdown style="font-size: xx-large;">
    <textarea data-template>
## More Teaching Resources

* Short and very practical introduction to data science: https://github.com/rasbt/data-science-tutorial
* Fundamentals of Machine Learning and Deep Learning in Python using Scikit-Learn, Keras and TensorFlow 2: https://github.com/ageron/handson-ml2
* CS231n: Convolutional Neural Networks for Visual Recognition: http://cs231n.stanford.edu/
* CS224n: Natural Language Processing with Deep Learning: http://web.stanford.edu/class/cs224n/index.html#schedule

</textarea>
    </section>


         <section data-markdown style="font-size: xx-large;">
            <textarea data-template>
### Finding data sets to play with
    
* Google released a search engine for datasets
  * Search: https://toolbox.google.com/datasetsearch
  * Launch blog post: https://www.blog.google/products/search/making-it-easier-discover-datasets/
* Kaggle Datasets: https://www.kaggle.com/datasets
* TensorFlow Datasets: https://medium.com/tensorflow/introducing-tensorflow-datasets-c7f01f7e19f3
* https://www.openml.org/search?type=data
* https://github.com/jbrownlee/Datasets
</textarea>
</section>

<section data-markdown style="font-size: xx-large;">
    <textarea data-template>
### More great stuff

* Depth estimation for monocular video: https://twitter.com/Reza_Zadeh/status/1256102964365680640
* Challenges when model should work for more than one customer: https://twitter.com/sh_reya/status/1254551364845240321

</textarea>
</section>



        </div>
    </div>

    <script src="reveal.js/js/reveal.js"></script>
    <script src="lib/jquery-2.2.4.js"></script>

    <script>
        $('section:not([data-background])').attr('data-background', "background/white.jpg");
    </script>
    <script>
        const isLocal = window.location.hostname.indexOf('localhost') !== -1 || 
                    window.location.hostname.indexOf('127.0.0.1') !== -1;

        $('.hide').remove();

        if (isLocal && !printMode) {
        } else {
            // only applies to public version
                $('.todo').remove();
                $('.preparation').remove();
                $('.local').remove();
        }
    
        Reveal.addEventListener( 'ready', function( event ) {
            // applies to all versions
            $('code').addClass('line-numbers');
    
            $('.fragments li').addClass('fragment')
    
            // make all links open in new tab
            $('a').attr('target', '_blank')
    
            if (isLocal && !printMode) {
                // only applies to presentation version
                Reveal.configure({ controls: false });
            } else {
                // only applies to public version
                $('.fragment').removeClass('fragment');
            }
    
    
        } );
    </script>
    
    <script>
        // More info about config & dependencies:
        // - https://github.com/hakimel/reveal.js#configuration
        // - https://github.com/hakimel/reveal.js#dependencies
        Reveal.initialize({
            controls: true,
            progress: false,
            history: true,
            center: true,
            width: 1100,

            math: {
                mathjax: 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js',
                config: 'TeX-AMS_HTML-full'  // See http://docs.mathjax.org/en/latest/config-files.html
            },

            dependencies: [
                { src: 'reveal.js/plugin/markdown/marked.js' },
                { src: 'reveal.js/plugin/markdown/markdown.js' },
                { src: 'reveal.js/plugin/notes/notes.js', async: true },
                { src: 'reveal.js/plugin/highlight/highlight.js', async: true },
                { src: 'lib/js/line-numbers.js' },
                { src: 'reveal.js/plugin/math/math.js', async: true }
            ]
        });
    </script>
</body>

</html>