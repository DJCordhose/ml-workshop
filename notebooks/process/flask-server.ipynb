{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "flask-server.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [
        "FASceuwQAOTp",
        "_px_mArrS4Um",
        "ls7X_oTmUC5q"
      ],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DJCordhose/ml-workshop/blob/master/notebooks/process/flask-server.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "5hBDJrqDAOTW"
      },
      "source": [
        "# Serving using Flask\n",
        "\n",
        "Links\n",
        "* making flask server directly run on Colab: https://stackoverflow.com/questions/54465816/how-to-use-flask-in-google-colaboratory-python-notebook\n",
        "* logging\n",
        "  * https://flask.palletsprojects.com/en/1.1.x/logging/\n",
        "  * https://docs.python.org/3/howto/logging-cookbook.html\n",
        "* In a real production environment you would either use a \"real\" web server that directs to flask or use a hosted solution\n",
        "  * https://flask.palletsprojects.com/en/1.1.x/deploying/\n",
        "  * https://en.wikipedia.org/wiki/Web_Server_Gateway_Interface"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cLJDjtH0Lrs3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "smgb3AXhuNAq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "dd878574-e3a4-4a12-90df-b1b98e1ffc7e"
      },
      "source": [
        "!curl -O https://raw.githubusercontent.com/DJCordhose/ml-workshop/master/prod/prod.tgz"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "\r  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\r  2 64710    2  1919    0     0   9943      0  0:00:06 --:--:--  0:00:06  9891\r100 64710  100 64710    0     0   305k      0 --:--:-- --:--:-- --:--:--  303k\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h0cOv-WXzFnv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!tar -xzf prod.tgz"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tJvGCJssGKpN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 578
        },
        "outputId": "c732e382-5466-4dc9-e755-855ede395971"
      },
      "source": [
        "!ls -lR"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            ".:\n",
            "total 392\n",
            "drwxr-xr-x 2 root root   4096 Jul 23 07:35 data\n",
            "-rw-r--r-- 1 root root      5 Jul 23 10:43 data.log\n",
            "-rw-r--r-- 1 root root  26863 Jul 23 07:52 export.ipynb\n",
            "drwxr-xr-x 2 root root   4096 Jul 23 07:31 models\n",
            "-rw-r--r-- 1 root root  64710 Jul 23 10:57 prod.tgz\n",
            "-rw-r--r-- 1 root root 283958 Jul 23 07:32 rf.model\n",
            "drwxr-xr-x 1 root root   4096 Jul 19 16:14 sample_data\n",
            "drwxr-xr-x 2 root root   4096 Jul 23 07:35 stats\n",
            "\n",
            "./data:\n",
            "total 28\n",
            "-rw-r--r-- 1 root root 26783 Jul 23 07:52 insurance-customers-1500.csv\n",
            "\n",
            "./models:\n",
            "total 280\n",
            "-rw-r--r-- 1 root root 284103 Jul 23 07:52 rf.model\n",
            "\n",
            "./sample_data:\n",
            "total 55504\n",
            "-r-xr-xr-x 1 root root     1697 Jan  1  2000 anscombe.json\n",
            "-rw-r--r-- 1 root root   301141 Jul 19 16:14 california_housing_test.csv\n",
            "-rw-r--r-- 1 root root  1706430 Jul 19 16:14 california_housing_train.csv\n",
            "-rw-r--r-- 1 root root 18289443 Jul 19 16:14 mnist_test.csv\n",
            "-rw-r--r-- 1 root root 36523880 Jul 19 16:14 mnist_train_small.csv\n",
            "-r-xr-xr-x 1 root root      930 Jan  1  2000 README.md\n",
            "\n",
            "./stats:\n",
            "total 12\n",
            "-rw-r--r-- 1 root root 1145 Jul 23 07:52 describe.pickle\n",
            "-rw-r--r-- 1 root root  332 Jul 23 07:52 scores.pickle\n",
            "-rw-r--r-- 1 root root   86 Jul 23 07:52 versions.pickle\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "53aeclH4z1qj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pickle"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bGVJ9Mwyz26R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_versions = pickle.load(open('stats/versions.pickle', 'rb'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qu31y9Re7363",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy, sklearn, pandas\n",
        "\n",
        "versions = {\n",
        "    'numpy': numpy.__version__,\n",
        "    'sklearn': sklearn.__version__, \n",
        "    'pandas': pandas.__version__\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jbvG3C-A0Adi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "assert model_versions == versions"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dZ7ZffV7Vk9t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import logging\n",
        "\n",
        "logging.basicConfig(filename='req.log')\n",
        "\n",
        "data_logger = logging.getLogger('DataLogger')\n",
        "data_logger.setLevel(logging.INFO)\n",
        "\n",
        "file_handler = logging.FileHandler('data.log', )\n",
        "\n",
        "data_logger.addHandler(file_handler)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yWyTjqlvBWON",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# loading models only once on startup\n",
        "model = pickle.load(open('models/rf.model', 'rb'))\n",
        "\n",
        "# speed_std_scale = pickle.load(open('models/speed_std_scale.model', 'rb'))\n",
        "# age_std_scale = pickle.load(open('models/age_std_scale.model', 'rb'))\n",
        "# miles_std_scale = pickle.load(open('models/miles_std_scale.model', 'rb'))\n",
        "\n",
        "def predict(speed, age, miles):\n",
        "#     sample = [[speed_std_scale.transform([speed])[0],\n",
        "#                age_std_scale.transform([age])[0],\n",
        "#                miles_std_scale.transform([miles])[0]]]\n",
        "    sample = [[speed, age, miles]]\n",
        "\n",
        "    result = int(model.predict(sample)[0])\n",
        "    prediction = model.predict_proba(sample)[0].tolist()\n",
        "    \n",
        "    return result, prediction"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aQLlcVkkJHdw",
        "colab_type": "code",
        "outputId": "f8d233d3-e229-452f-a72e-9cf67cd0fe9a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "predict(100, 48, 10)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, [0.10544217687074829, 0.6598639455782314, 0.2346938775510204])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7WBvg3rP6Dgf",
        "colab_type": "code",
        "outputId": "97063f40-adc4-4208-f538-096ff0ab5aef",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "from flask import Flask, request, jsonify\n",
        "import socket\n",
        "print(socket.gethostbyname(socket.getfqdn(socket.gethostname())))\n",
        "\n",
        "app = Flask(__name__)\n",
        "\n",
        "@app.route(\"/ping\")\n",
        "def ping():\n",
        "    return \"pong\"\n",
        "\n",
        "@app.route('/predict', methods=['GET', 'POST'])\n",
        "def do_predict():\n",
        "    speed = request.json['speed']\n",
        "    age = request.json['age']\n",
        "    miles = request.json['miles']\n",
        "\n",
        "    predicted_category, probabilities = predict(speed, age, miles)\n",
        "\n",
        "    response = {\n",
        "        'category': predicted_category,\n",
        "        'prediction': probabilities,\n",
        "    }\n",
        "    \n",
        "    dataset = {\n",
        "        'out': response,\n",
        "        'in': {\n",
        "            'speed': speed, 'age': age, 'miles': miles\n",
        "        }\n",
        "    }\n",
        "\n",
        "    data_logger.info(dataset)\n",
        "\n",
        "    return jsonify(response)\n",
        "  \n",
        "import threading\n",
        "threading.Thread(target=app.run, kwargs={'host': '0.0.0.0', 'port': 80}).start()  "
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "172.28.0.2\n",
            " * Serving Flask app \"__main__\" (lazy loading)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1oPj8OQy-kwL",
        "colab_type": "code",
        "outputId": "530146c9-d98b-418b-cfc1-a852d661c792",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "import requests\n",
        "r = requests.get(\"http://172.28.0.2/ping\")\n",
        "print(r.status_code)\n",
        "print(r.encoding)\n",
        "print(r.apparent_encoding)\n",
        "print(r.text)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " * Environment: production\n",
            "   WARNING: This is a development server. Do not use it in a production deployment.\n",
            "   Use a production WSGI server instead.\n",
            " * Debug mode: off\n",
            "200\n",
            "utf-8\n",
            "ascii\n",
            "pong\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h71anuhb-vRL",
        "colab_type": "code",
        "outputId": "7fde8eac-4673-432f-ce69-b8ec7052cdbb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "r = requests.post(\"http://172.28.0.2/predict\", json={'speed': 100, 'age': 48, 'miles': 10})\n",
        "r.status_code"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "200"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ENXdyPiJ_dn",
        "colab_type": "code",
        "outputId": "2c5652d3-852b-4d6b-d387-6cb5bc82866a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "response = r.json()\n",
        "response"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'category': 1,\n",
              " 'prediction': [0.10544217687074829, 0.6598639455782314, 0.2346938775510204]}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ul5_8C3JLz79",
        "colab_type": "code",
        "outputId": "523cca5f-c173-462e-b6f4-34da45eb47f0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "response['prediction']"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.10544217687074829, 0.6598639455782314, 0.2346938775510204]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tCSMdE_XL_dO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "10b4adc5-9199-44bb-be89-47e9e967fe4a"
      },
      "source": [
        "!cat data.log"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Huhu\n",
            "{'out': {'category': 1, 'prediction': [0.10544217687074829, 0.6598639455782314, 0.2346938775510204]}, 'in': {'speed': 100, 'age': 48, 'miles': 10}}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dZUG9Zl9e1PE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}