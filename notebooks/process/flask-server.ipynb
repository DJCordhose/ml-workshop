{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "flask-server.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [
        "FASceuwQAOTp",
        "_px_mArrS4Um",
        "ls7X_oTmUC5q"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DJCordhose/ml-workshop/blob/master/notebooks/process/flask-server.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "5hBDJrqDAOTW"
      },
      "source": [
        "# Serving using Flask\n",
        "\n",
        "Links\n",
        "* making flask server directly run on Colab: https://stackoverflow.com/questions/54465816/how-to-use-flask-in-google-colaboratory-python-notebook"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sSLuIxs0Babl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "901917d9-5958-47eb-f588-49e7e89beeab"
      },
      "source": [
        "!ls -l"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total 4\n",
            "drwxr-xr-x 1 root root 4096 Jul  3 16:14 sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yWyTjqlvBWON",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 232
        },
        "outputId": "38e1f0b1-1fcc-40e9-987d-857e1730c583"
      },
      "source": [
        "import pickle\n",
        "\n",
        "# loading models only once on startup\n",
        "model = pickle.load(open('models/dt.model', 'rb'))\n",
        "\n",
        "y_le = pickle.load(open('models/y_le.model', 'rb'))\n",
        "speed_std_scale = pickle.load(open('models/speed_std_scale.model', 'rb'))\n",
        "age_std_scale = pickle.load(open('models/age_std_scale.model', 'rb'))\n",
        "miles_std_scale = pickle.load(open('models/miles_std_scale.model', 'rb'))\n",
        "\n",
        "def predict(speed, age, miles):\n",
        "    sample = [[speed_std_scale.transform([speed])[0],\n",
        "               age_std_scale.transform([age])[0],\n",
        "               miles_std_scale.transform([miles])[0]]]\n",
        "\n",
        "    result = model.predict(sample)\n",
        "    result_group = y_le.inverse_transform(result)[0]\n",
        "    prediction = model.predict_proba(sample)[0].tolist()\n",
        "    \n",
        "    return result_group, prediction, y_le.classes_.tolist()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-2c6aa32f0a17>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# loading models only once on startup\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'models/dt.model'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0my_le\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'models/y_le.model'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'models/dt.model'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7WBvg3rP6Dgf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "d8ed6697-f29c-4aca-ea4a-65b75cbffef3"
      },
      "source": [
        "from flask import Flask, request, jsonify\n",
        "import socket\n",
        "print(socket.gethostbyname(socket.getfqdn(socket.gethostname())))\n",
        "\n",
        "app = Flask(__name__)\n",
        "\n",
        "@app.route(\"/ping\")\n",
        "def ping():\n",
        "    return \"pong\"\n",
        "\n",
        "@app.route('/', methods=['GET', 'POST'])\n",
        "def do_predict():\n",
        "    speed = request.json['speed']\n",
        "    age = request.json['age']\n",
        "    miles = request.json['miles']\n",
        "\n",
        "    predicted_category, probabilities, classes = predict(speed, age, miles)\n",
        "    # print ('predicted_category:', predicted_category)\n",
        "    # print ('prediction:', prediction)\n",
        "\n",
        "    response = {\n",
        "        'category': predicted_category,\n",
        "        'prediction': probabilities,\n",
        "        'classes': classes\n",
        "    }\n",
        "    return jsonify(response)\n",
        "  \n",
        "import threading\n",
        "threading.Thread(target=app.run, kwargs={'host': '0.0.0.0', 'port': 80}).start()  "
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "172.28.0.2\n",
            " * Serving Flask app \"__main__\" (lazy loading)\n",
            " * Environment: production\n",
            "   WARNING: This is a development server. Do not use it in a production deployment.\n",
            "   Use a production WSGI server instead.\n",
            " * Debug mode: off\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1oPj8OQy-kwL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "2a8cefc7-2b93-49d6-af2f-9c16e32a1e9a"
      },
      "source": [
        "import requests\n",
        "r = requests.get(\"http://172.28.0.2/ping\")\n",
        "print(r.status_code)\n",
        "print(r.encoding)\n",
        "print(r.apparent_encoding)\n",
        "print(r.text)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " * Running on http://0.0.0.0:80/ (Press CTRL+C to quit)\n",
            "172.28.0.2 - - [22/Jul/2019 14:10:29] \"\u001b[37mGET /ping HTTP/1.1\u001b[0m\" 200 -\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "200\n",
            "utf-8\n",
            "ascii\n",
            "pong\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h71anuhb-vRL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}