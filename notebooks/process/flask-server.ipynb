{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "flask-server.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [
        "FASceuwQAOTp",
        "_px_mArrS4Um",
        "ls7X_oTmUC5q"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DJCordhose/ml-workshop/blob/master/notebooks/process/flask-server.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "5hBDJrqDAOTW"
      },
      "source": [
        "# Serving using Flask\n",
        "\n",
        "Links\n",
        "* making flask server directly run on Colab: https://stackoverflow.com/questions/54465816/how-to-use-flask-in-google-colaboratory-python-notebook"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cLJDjtH0Lrs3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sSLuIxs0Babl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "9aa2e91d-840a-4b78-dbb4-a3a9ad034095"
      },
      "source": [
        "!ls -l"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total 280\n",
            "drwxr-xr-x 2 root root   4096 Jul 22 14:43 models\n",
            "-rw-r--r-- 1 root root 277537 Jul 22 14:42 rf.model\n",
            "drwxr-xr-x 1 root root   4096 Jul  3 16:14 sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yWyTjqlvBWON",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pickle\n",
        "\n",
        "# loading models only once on startup\n",
        "model = pickle.load(open('models/rf.model', 'rb'))\n",
        "\n",
        "# speed_std_scale = pickle.load(open('models/speed_std_scale.model', 'rb'))\n",
        "# age_std_scale = pickle.load(open('models/age_std_scale.model', 'rb'))\n",
        "# miles_std_scale = pickle.load(open('models/miles_std_scale.model', 'rb'))\n",
        "\n",
        "def predict(speed, age, miles):\n",
        "#     sample = [[speed_std_scale.transform([speed])[0],\n",
        "#                age_std_scale.transform([age])[0],\n",
        "#                miles_std_scale.transform([miles])[0]]]\n",
        "    sample = [[speed, age, miles]]\n",
        "\n",
        "    result = int(model.predict(sample)[0])\n",
        "    prediction = model.predict_proba(sample)[0].tolist()\n",
        "    \n",
        "    return result, prediction"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aQLlcVkkJHdw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "75621ef9-491a-4c14-f47d-1a0a31f98ea4"
      },
      "source": [
        "predict(100, 48, 10)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, [0.07023809523809524, 0.6569444444444444, 0.2728174603174603])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7WBvg3rP6Dgf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "f75ada72-2d12-465c-9eaa-31869fb4bcc3"
      },
      "source": [
        "from flask import Flask, request, jsonify\n",
        "import socket\n",
        "print(socket.gethostbyname(socket.getfqdn(socket.gethostname())))\n",
        "\n",
        "app = Flask(__name__)\n",
        "\n",
        "@app.route(\"/ping\")\n",
        "def ping():\n",
        "    return \"pong\"\n",
        "\n",
        "@app.route('/predict', methods=['GET', 'POST'])\n",
        "def do_predict():\n",
        "    speed = request.json['speed']\n",
        "    age = request.json['age']\n",
        "    miles = request.json['miles']\n",
        "\n",
        "    predicted_category, probabilities = predict(speed, age, miles)\n",
        "\n",
        "    response = {\n",
        "        'category': predicted_category,\n",
        "        'prediction': probabilities,\n",
        "    }\n",
        "    return jsonify(response)\n",
        "  \n",
        "import threading\n",
        "threading.Thread(target=app.run, kwargs={'host': '0.0.0.0', 'port': 80}).start()  "
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "172.28.0.2\n",
            " * Serving Flask app \"__main__\" (lazy loading)\n",
            " * Environment: production\n",
            "   WARNING: This is a development server. Do not use it in a production deployment.\n",
            "   Use a production WSGI server instead.\n",
            " * Debug mode: off\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1oPj8OQy-kwL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "6bec879a-9e43-43be-8688-54eaf70623da"
      },
      "source": [
        "import requests\n",
        "r = requests.get(\"http://172.28.0.2/ping\")\n",
        "print(r.status_code)\n",
        "print(r.encoding)\n",
        "print(r.apparent_encoding)\n",
        "print(r.text)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "172.28.0.2 - - [22/Jul/2019 14:55:34] \"\u001b[37mGET /ping HTTP/1.1\u001b[0m\" 200 -\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "200\n",
            "utf-8\n",
            "ascii\n",
            "pong\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h71anuhb-vRL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "c9ecc335-d087-4f9e-9134-50d3ecb2810f"
      },
      "source": [
        "r = requests.post(\"http://172.28.0.2/predict\", json={'speed': 100, 'age': 48, 'miles': 10})\n",
        "r.status_code"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "172.28.0.2 - - [22/Jul/2019 14:57:03] \"\u001b[37mPOST /predict HTTP/1.1\u001b[0m\" 200 -\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "200"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ENXdyPiJ_dn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "2241fbeb-5f48-4d91-cf0a-43c086c0a8e6"
      },
      "source": [
        "response = r.json()\n",
        "response"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'category': 1,\n",
              " 'prediction': [0.07023809523809524, 0.6569444444444444, 0.2728174603174603]}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ul5_8C3JLz79",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "781ab514-1c63-4f94-8387-6412b6f1c19c"
      },
      "source": [
        "response['prediction']"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.07023809523809524, 0.6569444444444444, 0.2728174603174603]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tCSMdE_XL_dO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}